{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import TripletAudio\n",
    "from networks import AnchorNet, EmbeddingNet, TripletNet\n",
    "from losses import TripletLoss\n",
    "import torch.optim as optim\n",
    "from recall import Recall\n",
    "from torch.optim import lr_scheduler\n",
    "from trainer import fit\n",
    "from recall import Recall\n",
    "import itertools\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define hyperparams\n",
    "K, MAX_CLOSE_NEG, P_STRONG_NEG = 5, 15, 1\n",
    "BATCH_SIZE = 128\n",
    "INPUT_D, OUTPUT_D = 192, 128\n",
    "MARGIN, N_EPOCHS, LOG_INT, N_RECALL_CAND = 0.5, 20, 100, 25\n",
    "N_RECALL_SAMPLES = 1000\n",
    "LEARNING_RATE, STEP_SIZE, GAMMA = 1e-3, 15, 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes the recall on datasets using global variables such as model and recall\n",
    "def measure_recall(datasets):\n",
    "    outputs = []\n",
    "    for d in datasets:\n",
    "        batch_indicies = np.random.choice(list(range(0, d.get_dataset().shape[0])), N_RECALL_SAMPLES, False)\n",
    "        queries = d.get_dataset()[batch_indicies]\n",
    "        knns_of_batch = d.get_knn().iloc[batch_indicies, :]\n",
    "        outputs.append(recall.calculate(d.get_dataset(), model.embedding_net, queries, knns_of_batch, False))\n",
    "    return [np.mean(x) for x in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for (LEARNING_RATE, STEP_SIZE, GAMMA) in itertools.product(*hyperparams):\n",
    "#setup datasets\n",
    "cuda = torch.cuda.is_available()\n",
    "triplet_train_dataset = TripletAudio(True, K, MAX_CLOSE_NEG, P_STRONG_NEG)\n",
    "triplet_test_dataset = TripletAudio(False, K, MAX_CLOSE_NEG, P_STRONG_NEG)\n",
    "triplet_train_loader = torch.utils.data.DataLoader(triplet_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "triplet_test_loader = torch.utils.data.DataLoader(triplet_test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "#define model \n",
    "embedding_net = EmbeddingNet()\n",
    "model = TripletNet(embedding_net)\n",
    "if cuda:\n",
    "    print(\"GPU Enabled\")\n",
    "    model.cuda()\n",
    "loss_fn = TripletLoss(MARGIN)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA, last_epoch=-1)\n",
    "recall = Recall(N_RECALL_CAND, K)\n",
    "#run the model\n",
    "train_loss, val_loss = fit(triplet_train_loader, triplet_test_loader, model, loss_fn, optimizer, scheduler, N_EPOCHS, cuda, LOG_INT)\n",
    "#measure recall\n",
    "train_recall, val_recall = measure_recall([triplet_train_dataset, triplet_test_dataset])\n",
    "#write to tensorboard\n",
    "with SummaryWriter() as w:\n",
    "    w.add_hparams(\n",
    "        {'LEARNING_RATE': LEARNING_RATE, 'GAMMA': GAMMA, 'STEP_SIZE': STEP_SIZE, 'BSIZE': BATCH_SIZE, 'N_RECALL_S': N_RECALL_SAMPLES, 'N_RECALL_CAND': N_RECALL_CAND,\n",
    "             'CLOSE_NEG': MAX_CLOSE_NEG, 'P_STRONG_NEG': P_STRONG_NEG, 'OUTPUT_D': OUTPUT_D},\n",
    "        {'TRAIN_L': train_loss, 'VAL_L': val_loss, 'TRAIN_RECALL': train_recall, 'VAL_RECALL': val_recall})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.pyplot.pie([len(x) for x in recall.bucket_hash.hash.values()]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.randn(50,192)\n",
    "output = embedding_net(temp)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "415px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

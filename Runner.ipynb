{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import TripletAudio\n",
    "from networks import AnchorNet, EmbeddingNet, TripletNet\n",
    "from losses import TripletLoss\n",
    "import torch.optim as optim\n",
    "from recall import Recall\n",
    "from torch.optim import lr_scheduler\n",
    "from trainer import fit\n",
    "from recall import Recall\n",
    "import itertools\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define hyperparams\n",
    "K, MAX_CLOSE_NEG, P_STRONG_NEG = 5, 15, 1\n",
    "BATCH_SIZE = 128\n",
    "INPUT_D, OUTPUT_D = 192, 128\n",
    "MARGIN, N_EPOCHS, LOG_INT, N_RECALL_CAND = 0.5, 20, 100, 25\n",
    "N_RECALL_SAMPLES = 1000\n",
    "# hyperparams = [P_STRONG_NEGS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes the recall on datasets using global variables such as model and recall\n",
    "def measure_recall(datasets):\n",
    "    outputs = []\n",
    "    for d in datasets:\n",
    "        batch_indicies = np.random.choice(list(range(0, d.get_dataset().shape[0])), N_RECALL_SAMPLES, False)\n",
    "        queries = d.get_dataset()[batch_indicies]\n",
    "        knns_of_batch = d.get_knn().iloc[batch_indicies, :]\n",
    "        outputs.append(recall.calculate(d.get_dataset(), model.embedding_net, queries, knns_of_batch, False))\n",
    "    return [np.mean(x) for x in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialising model biases\n",
      "done\n",
      "Train: [0/48048 (0%)]\tLoss: 15.933144\n",
      "Train: [12800/48048 (27%)]\tLoss: 16.671302\n",
      "Train: [25600/48048 (53%)]\tLoss: 15.290250\n",
      "Train: [38400/48048 (80%)]\tLoss: 15.189563\n",
      "Epoch: 1/20. Train set: Average loss: 15.4895\n",
      "Epoch: 1/20. Validation set: Average loss: 16.9150\n",
      "Train: [0/48048 (0%)]\tLoss: 11.316054\n",
      "Train: [12800/48048 (27%)]\tLoss: 13.119747\n",
      "Train: [25600/48048 (53%)]\tLoss: 12.338122\n",
      "Train: [38400/48048 (80%)]\tLoss: 11.385098\n",
      "Epoch: 2/20. Train set: Average loss: 11.8998\n",
      "Epoch: 2/20. Validation set: Average loss: 11.9876\n",
      "Train: [0/48048 (0%)]\tLoss: 11.608500\n",
      "Train: [12800/48048 (27%)]\tLoss: 8.862409\n",
      "Train: [25600/48048 (53%)]\tLoss: 8.076705\n",
      "Train: [38400/48048 (80%)]\tLoss: 7.750642\n",
      "Epoch: 3/20. Train set: Average loss: 7.9997\n",
      "Epoch: 3/20. Validation set: Average loss: 8.0638\n",
      "Train: [0/48048 (0%)]\tLoss: 6.586010\n",
      "Train: [12800/48048 (27%)]\tLoss: 6.257767\n",
      "Train: [25600/48048 (53%)]\tLoss: 5.837694\n",
      "Train: [38400/48048 (80%)]\tLoss: 5.068677\n",
      "Epoch: 4/20. Train set: Average loss: 5.6282\n",
      "Epoch: 4/20. Validation set: Average loss: 5.6196\n",
      "Train: [0/48048 (0%)]\tLoss: 4.250651\n",
      "Train: [12800/48048 (27%)]\tLoss: 4.297706\n",
      "Train: [25600/48048 (53%)]\tLoss: 4.338202\n",
      "Train: [38400/48048 (80%)]\tLoss: 4.118420\n",
      "Epoch: 5/20. Train set: Average loss: 4.0995\n",
      "Epoch: 5/20. Validation set: Average loss: 4.1493\n",
      "Train: [0/48048 (0%)]\tLoss: 5.152709\n",
      "Train: [12800/48048 (27%)]\tLoss: 3.466528\n",
      "Train: [25600/48048 (53%)]\tLoss: 3.491198\n",
      "Train: [38400/48048 (80%)]\tLoss: 3.330462\n",
      "Epoch: 6/20. Train set: Average loss: 3.3149\n",
      "Epoch: 6/20. Validation set: Average loss: 3.3503\n",
      "Train: [0/48048 (0%)]\tLoss: 2.370784\n",
      "Train: [12800/48048 (27%)]\tLoss: 3.011395\n",
      "Train: [25600/48048 (53%)]\tLoss: 2.715413\n",
      "Train: [38400/48048 (80%)]\tLoss: 2.649129\n",
      "Epoch: 7/20. Train set: Average loss: 2.7417\n",
      "Epoch: 7/20. Validation set: Average loss: 2.7154\n",
      "Train: [0/48048 (0%)]\tLoss: 1.540440\n",
      "Train: [12800/48048 (27%)]\tLoss: 2.527700\n",
      "Train: [25600/48048 (53%)]\tLoss: 2.451831\n",
      "Train: [38400/48048 (80%)]\tLoss: 2.096749\n",
      "Epoch: 8/20. Train set: Average loss: 2.2820\n",
      "Epoch: 8/20. Validation set: Average loss: 2.3029\n",
      "Train: [0/48048 (0%)]\tLoss: 2.967706\n",
      "Train: [12800/48048 (27%)]\tLoss: 2.102874\n",
      "Train: [25600/48048 (53%)]\tLoss: 2.193109\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.976104\n",
      "Epoch: 9/20. Train set: Average loss: 2.0285\n",
      "Epoch: 9/20. Validation set: Average loss: 2.0571\n",
      "Train: [0/48048 (0%)]\tLoss: 1.321283\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.771078\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.772259\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.805863\n",
      "Epoch: 10/20. Train set: Average loss: 1.7680\n",
      "Epoch: 10/20. Validation set: Average loss: 1.8893\n",
      "Train: [0/48048 (0%)]\tLoss: 0.852900\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.717751\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.574519\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.742218\n",
      "Epoch: 11/20. Train set: Average loss: 1.6397\n",
      "Epoch: 11/20. Validation set: Average loss: 1.7832\n",
      "Train: [0/48048 (0%)]\tLoss: 3.079271\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.473169\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.481756\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.507939\n",
      "Epoch: 12/20. Train set: Average loss: 1.4800\n",
      "Epoch: 12/20. Validation set: Average loss: 1.6936\n",
      "Train: [0/48048 (0%)]\tLoss: 4.042948\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.503042\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.496512\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.409496\n",
      "Epoch: 13/20. Train set: Average loss: 1.4815\n",
      "Epoch: 13/20. Validation set: Average loss: 1.6098\n",
      "Train: [0/48048 (0%)]\tLoss: 1.788736\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.175248\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.271809\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.357680\n",
      "Epoch: 14/20. Train set: Average loss: 1.2700\n",
      "Epoch: 14/20. Validation set: Average loss: 1.5429\n",
      "Train: [0/48048 (0%)]\tLoss: 0.595477\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.256461\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.348855\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.235631\n",
      "Epoch: 15/20. Train set: Average loss: 1.2791\n",
      "Epoch: 15/20. Validation set: Average loss: 1.4905\n",
      "Train: [0/48048 (0%)]\tLoss: 0.606414\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.244209\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.236877\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.255467\n",
      "Epoch: 16/20. Train set: Average loss: 1.2382\n",
      "Epoch: 16/20. Validation set: Average loss: 1.4613\n",
      "Train: [0/48048 (0%)]\tLoss: 1.926284\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.170957\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.206044\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.153558\n",
      "Epoch: 17/20. Train set: Average loss: 1.1577\n",
      "Epoch: 17/20. Validation set: Average loss: 1.4285\n",
      "Train: [0/48048 (0%)]\tLoss: 1.331804\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.170679\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.182917\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.119307\n",
      "Epoch: 18/20. Train set: Average loss: 1.1499\n",
      "Epoch: 18/20. Validation set: Average loss: 1.4045\n",
      "Train: [0/48048 (0%)]\tLoss: 1.671966\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.125340\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.250210\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.025438\n",
      "Epoch: 19/20. Train set: Average loss: 1.1363\n",
      "Epoch: 19/20. Validation set: Average loss: 1.3862\n",
      "Train: [0/48048 (0%)]\tLoss: 0.511550\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.159084\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.068019\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.028770\n",
      "Epoch: 20/20. Train set: Average loss: 1.0854\n",
      "Epoch: 20/20. Validation set: Average loss: 1.3575\n",
      "embedding dataset\n",
      "quantizing dataset\n",
      "done quantizing into 626 buckets\n",
      "embedding dataset\n",
      "quantizing dataset\n",
      "done quantizing into 131 buckets\n",
      "initialising model biases\n",
      "done\n",
      "Train: [0/48048 (0%)]\tLoss: 13.952196\n",
      "Train: [12800/48048 (27%)]\tLoss: 15.716089\n",
      "Train: [25600/48048 (53%)]\tLoss: 16.024186\n",
      "Train: [38400/48048 (80%)]\tLoss: 16.189768\n",
      "Epoch: 1/20. Train set: Average loss: 15.5699\n",
      "Epoch: 1/20. Validation set: Average loss: 17.3781\n",
      "Train: [0/48048 (0%)]\tLoss: 7.979755\n",
      "Train: [12800/48048 (27%)]\tLoss: 13.483774\n",
      "Train: [25600/48048 (53%)]\tLoss: 12.426242\n",
      "Train: [38400/48048 (80%)]\tLoss: 11.629981\n",
      "Epoch: 2/20. Train set: Average loss: 12.0371\n",
      "Epoch: 2/20. Validation set: Average loss: 12.5208\n",
      "Train: [0/48048 (0%)]\tLoss: 9.102097\n",
      "Train: [12800/48048 (27%)]\tLoss: 9.519442\n",
      "Train: [25600/48048 (53%)]\tLoss: 8.703409\n",
      "Train: [38400/48048 (80%)]\tLoss: 7.909424\n",
      "Epoch: 3/20. Train set: Average loss: 8.4412\n",
      "Epoch: 3/20. Validation set: Average loss: 8.4974\n",
      "Train: [0/48048 (0%)]\tLoss: 8.107843\n",
      "Train: [12800/48048 (27%)]\tLoss: 6.539125\n",
      "Train: [25600/48048 (53%)]\tLoss: 5.852935\n",
      "Train: [38400/48048 (80%)]\tLoss: 5.740045\n",
      "Epoch: 4/20. Train set: Average loss: 5.8485\n",
      "Epoch: 4/20. Validation set: Average loss: 5.7520\n",
      "Train: [0/48048 (0%)]\tLoss: 4.830441\n",
      "Train: [12800/48048 (27%)]\tLoss: 4.877030\n",
      "Train: [25600/48048 (53%)]\tLoss: 4.433089\n",
      "Train: [38400/48048 (80%)]\tLoss: 3.672196\n",
      "Epoch: 5/20. Train set: Average loss: 4.2362\n",
      "Epoch: 5/20. Validation set: Average loss: 4.2509\n",
      "Train: [0/48048 (0%)]\tLoss: 3.293165\n",
      "Train: [12800/48048 (27%)]\tLoss: 3.709878\n",
      "Train: [25600/48048 (53%)]\tLoss: 3.482691\n",
      "Train: [38400/48048 (80%)]\tLoss: 3.266903\n",
      "Epoch: 6/20. Train set: Average loss: 3.4022\n",
      "Epoch: 6/20. Validation set: Average loss: 3.4141\n",
      "Train: [0/48048 (0%)]\tLoss: 2.771654\n",
      "Train: [12800/48048 (27%)]\tLoss: 2.666064\n",
      "Train: [25600/48048 (53%)]\tLoss: 2.791381\n",
      "Train: [38400/48048 (80%)]\tLoss: 2.501371\n",
      "Epoch: 7/20. Train set: Average loss: 2.5797\n",
      "Epoch: 7/20. Validation set: Average loss: 2.7808\n",
      "Train: [0/48048 (0%)]\tLoss: 3.748435\n",
      "Train: [12800/48048 (27%)]\tLoss: 2.221053\n",
      "Train: [25600/48048 (53%)]\tLoss: 2.160530\n",
      "Train: [38400/48048 (80%)]\tLoss: 2.270864\n",
      "Epoch: 8/20. Train set: Average loss: 2.2049\n",
      "Epoch: 8/20. Validation set: Average loss: 2.3783\n",
      "Train: [0/48048 (0%)]\tLoss: 3.302978\n",
      "Train: [12800/48048 (27%)]\tLoss: 2.162734\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.940432\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.718286\n",
      "Epoch: 9/20. Train set: Average loss: 1.9406\n",
      "Epoch: 9/20. Validation set: Average loss: 2.1380\n",
      "Train: [0/48048 (0%)]\tLoss: 4.434254\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.714292\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.758368\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.757763\n",
      "Epoch: 10/20. Train set: Average loss: 1.7555\n",
      "Epoch: 10/20. Validation set: Average loss: 1.9452\n",
      "Train: [0/48048 (0%)]\tLoss: 2.466818\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.664054\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.763143\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.639281\n",
      "Epoch: 11/20. Train set: Average loss: 1.6610\n",
      "Epoch: 11/20. Validation set: Average loss: 1.7981\n",
      "Train: [0/48048 (0%)]\tLoss: 0.710975\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.670483\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.558398\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.438503\n",
      "Epoch: 12/20. Train set: Average loss: 1.5276\n",
      "Epoch: 12/20. Validation set: Average loss: 1.6818\n",
      "Train: [0/48048 (0%)]\tLoss: 0.773527\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.507198\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.346354\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.291230\n",
      "Epoch: 13/20. Train set: Average loss: 1.3730\n",
      "Epoch: 13/20. Validation set: Average loss: 1.5976\n",
      "Train: [0/48048 (0%)]\tLoss: 1.115856\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.254800\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.305751\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.255631\n",
      "Epoch: 14/20. Train set: Average loss: 1.2902\n",
      "Epoch: 14/20. Validation set: Average loss: 1.5663\n",
      "Train: [0/48048 (0%)]\tLoss: 1.730258\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.299061\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.358440\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.210356\n",
      "Epoch: 15/20. Train set: Average loss: 1.2722\n",
      "Epoch: 15/20. Validation set: Average loss: 1.5254\n",
      "Train: [0/48048 (0%)]\tLoss: 1.473519\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.162991\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.271709\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.196270\n",
      "Epoch: 16/20. Train set: Average loss: 1.1961\n",
      "Epoch: 16/20. Validation set: Average loss: 1.5106\n",
      "Train: [0/48048 (0%)]\tLoss: 1.250974\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.152745\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.225145\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.219387\n",
      "Epoch: 17/20. Train set: Average loss: 1.1836\n",
      "Epoch: 17/20. Validation set: Average loss: 1.4840\n",
      "Train: [0/48048 (0%)]\tLoss: 0.672173\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.174630\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.106590\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.036913\n",
      "Epoch: 18/20. Train set: Average loss: 1.1458\n",
      "Epoch: 18/20. Validation set: Average loss: 1.4710\n",
      "Train: [0/48048 (0%)]\tLoss: 0.895054\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.141218\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.067046\n",
      "Train: [38400/48048 (80%)]\tLoss: 0.989841\n",
      "Epoch: 19/20. Train set: Average loss: 1.0656\n",
      "Epoch: 19/20. Validation set: Average loss: 1.4581\n",
      "Train: [0/48048 (0%)]\tLoss: 0.495664\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.103695\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.182143\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.046620\n",
      "Epoch: 20/20. Train set: Average loss: 1.0815\n",
      "Epoch: 20/20. Validation set: Average loss: 1.4321\n",
      "embedding dataset\n",
      "quantizing dataset\n",
      "done quantizing into 599 buckets\n",
      "embedding dataset\n",
      "quantizing dataset\n",
      "done quantizing into 128 buckets\n",
      "initialising model biases\n",
      "done\n",
      "Train: [0/48048 (0%)]\tLoss: 20.024504\n",
      "Train: [12800/48048 (27%)]\tLoss: 16.348044\n",
      "Train: [25600/48048 (53%)]\tLoss: 16.237988\n",
      "Train: [38400/48048 (80%)]\tLoss: 15.256762\n",
      "Epoch: 1/20. Train set: Average loss: 15.7992\n",
      "Epoch: 1/20. Validation set: Average loss: 18.0382\n",
      "Train: [0/48048 (0%)]\tLoss: 11.938459\n",
      "Train: [12800/48048 (27%)]\tLoss: 13.346149\n",
      "Train: [25600/48048 (53%)]\tLoss: 12.462848\n",
      "Train: [38400/48048 (80%)]\tLoss: 10.984583\n",
      "Epoch: 2/20. Train set: Average loss: 11.8525\n",
      "Epoch: 2/20. Validation set: Average loss: 12.3701\n",
      "Train: [0/48048 (0%)]\tLoss: 7.491088\n",
      "Train: [12800/48048 (27%)]\tLoss: 9.387419\n",
      "Train: [25600/48048 (53%)]\tLoss: 7.862129\n",
      "Train: [38400/48048 (80%)]\tLoss: 6.873302\n",
      "Epoch: 3/20. Train set: Average loss: 7.6867\n",
      "Epoch: 3/20. Validation set: Average loss: 7.5207\n",
      "Train: [0/48048 (0%)]\tLoss: 3.914865\n",
      "Train: [12800/48048 (27%)]\tLoss: 6.096147\n",
      "Train: [25600/48048 (53%)]\tLoss: 5.190458\n",
      "Train: [38400/48048 (80%)]\tLoss: 4.764067\n",
      "Epoch: 4/20. Train set: Average loss: 5.1130\n",
      "Epoch: 4/20. Validation set: Average loss: 5.1670\n",
      "Train: [0/48048 (0%)]\tLoss: 3.531878\n",
      "Train: [12800/48048 (27%)]\tLoss: 4.002235\n",
      "Train: [25600/48048 (53%)]\tLoss: 3.615969\n",
      "Train: [38400/48048 (80%)]\tLoss: 3.600048\n",
      "Epoch: 5/20. Train set: Average loss: 3.6555\n",
      "Epoch: 5/20. Validation set: Average loss: 3.9782\n",
      "Train: [0/48048 (0%)]\tLoss: 1.788777\n",
      "Train: [12800/48048 (27%)]\tLoss: 3.375464\n",
      "Train: [25600/48048 (53%)]\tLoss: 3.005906\n",
      "Train: [38400/48048 (80%)]\tLoss: 2.767685\n",
      "Epoch: 6/20. Train set: Average loss: 2.9775\n",
      "Epoch: 6/20. Validation set: Average loss: 3.2821\n",
      "Train: [0/48048 (0%)]\tLoss: 2.047664\n",
      "Train: [12800/48048 (27%)]\tLoss: 2.675440\n",
      "Train: [25600/48048 (53%)]\tLoss: 2.303021\n",
      "Train: [38400/48048 (80%)]\tLoss: 2.451068\n",
      "Epoch: 7/20. Train set: Average loss: 2.4365\n",
      "Epoch: 7/20. Validation set: Average loss: 2.7607\n",
      "Train: [0/48048 (0%)]\tLoss: 1.764729\n",
      "Train: [12800/48048 (27%)]\tLoss: 2.049653\n",
      "Train: [25600/48048 (53%)]\tLoss: 2.038198\n",
      "Train: [38400/48048 (80%)]\tLoss: 2.122959\n",
      "Epoch: 8/20. Train set: Average loss: 2.0440\n",
      "Epoch: 8/20. Validation set: Average loss: 2.4531\n",
      "Train: [0/48048 (0%)]\tLoss: 1.278750\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.869765\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.848839\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.686928\n",
      "Epoch: 9/20. Train set: Average loss: 1.7951\n",
      "Epoch: 9/20. Validation set: Average loss: 2.2283\n",
      "Train: [0/48048 (0%)]\tLoss: 0.712801\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.816690\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.600653\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.660543\n",
      "Epoch: 10/20. Train set: Average loss: 1.6797\n",
      "Epoch: 10/20. Validation set: Average loss: 1.9882\n",
      "Train: [0/48048 (0%)]\tLoss: 0.550538\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.452449\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.584579\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.450439\n",
      "Epoch: 11/20. Train set: Average loss: 1.4929\n",
      "Epoch: 11/20. Validation set: Average loss: 1.8178\n",
      "Train: [0/48048 (0%)]\tLoss: 1.009875\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.414932\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.524964\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.366090\n",
      "Epoch: 12/20. Train set: Average loss: 1.4099\n",
      "Epoch: 12/20. Validation set: Average loss: 1.6951\n",
      "Train: [0/48048 (0%)]\tLoss: 0.738505\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.296192\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.267520\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.236047\n",
      "Epoch: 13/20. Train set: Average loss: 1.2408\n",
      "Epoch: 13/20. Validation set: Average loss: 1.6071\n",
      "Train: [0/48048 (0%)]\tLoss: 1.386237\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.378510\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.202770\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.116349\n",
      "Epoch: 14/20. Train set: Average loss: 1.2363\n",
      "Epoch: 14/20. Validation set: Average loss: 1.5249\n",
      "Train: [0/48048 (0%)]\tLoss: 0.527408\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.216926\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.229139\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.239285\n",
      "Epoch: 15/20. Train set: Average loss: 1.2174\n",
      "Epoch: 15/20. Validation set: Average loss: 1.4486\n",
      "Train: [0/48048 (0%)]\tLoss: 0.774473\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.178305\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.134715\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.145419\n",
      "Epoch: 16/20. Train set: Average loss: 1.1302\n",
      "Epoch: 16/20. Validation set: Average loss: 1.3981\n",
      "Train: [0/48048 (0%)]\tLoss: 0.464964\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.113538\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.083180\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.073967\n",
      "Epoch: 17/20. Train set: Average loss: 1.0976\n",
      "Epoch: 17/20. Validation set: Average loss: 1.3574\n",
      "Train: [0/48048 (0%)]\tLoss: 0.533769\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.072011\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.097854\n",
      "Train: [38400/48048 (80%)]\tLoss: 0.944418\n",
      "Epoch: 18/20. Train set: Average loss: 1.0473\n",
      "Epoch: 18/20. Validation set: Average loss: 1.3351\n",
      "Train: [0/48048 (0%)]\tLoss: 0.532218\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.006961\n",
      "Train: [25600/48048 (53%)]\tLoss: 0.925253\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.069799\n",
      "Epoch: 19/20. Train set: Average loss: 1.0064\n",
      "Epoch: 19/20. Validation set: Average loss: 1.3176\n",
      "Train: [0/48048 (0%)]\tLoss: 0.474489\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.012892\n",
      "Train: [25600/48048 (53%)]\tLoss: 0.903569\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.012343\n",
      "Epoch: 20/20. Train set: Average loss: 0.9914\n",
      "Epoch: 20/20. Validation set: Average loss: 1.2859\n",
      "embedding dataset\n",
      "quantizing dataset\n",
      "done quantizing into 600 buckets\n",
      "embedding dataset\n",
      "quantizing dataset\n",
      "done quantizing into 125 buckets\n",
      "initialising model biases\n",
      "done\n",
      "Train: [0/48048 (0%)]\tLoss: 20.171011\n",
      "Train: [12800/48048 (27%)]\tLoss: 17.191271\n",
      "Train: [25600/48048 (53%)]\tLoss: 15.942299\n",
      "Train: [38400/48048 (80%)]\tLoss: 15.392330\n",
      "Epoch: 1/20. Train set: Average loss: 15.9264\n",
      "Epoch: 1/20. Validation set: Average loss: 18.3393\n",
      "Train: [0/48048 (0%)]\tLoss: 13.456103\n",
      "Train: [12800/48048 (27%)]\tLoss: 13.265505\n",
      "Train: [25600/48048 (53%)]\tLoss: 12.356993\n",
      "Train: [38400/48048 (80%)]\tLoss: 11.481044\n",
      "Epoch: 2/20. Train set: Average loss: 11.8405\n",
      "Epoch: 2/20. Validation set: Average loss: 13.1732\n",
      "Train: [0/48048 (0%)]\tLoss: 12.543114\n",
      "Train: [12800/48048 (27%)]\tLoss: 9.232882\n",
      "Train: [25600/48048 (53%)]\tLoss: 7.997149\n",
      "Train: [38400/48048 (80%)]\tLoss: 7.146463\n",
      "Epoch: 3/20. Train set: Average loss: 7.7856\n",
      "Epoch: 3/20. Validation set: Average loss: 7.8823\n",
      "Train: [0/48048 (0%)]\tLoss: 4.209881\n",
      "Train: [12800/48048 (27%)]\tLoss: 5.892414\n",
      "Train: [25600/48048 (53%)]\tLoss: 5.030981\n",
      "Train: [38400/48048 (80%)]\tLoss: 4.638044\n",
      "Epoch: 4/20. Train set: Average loss: 5.0721\n",
      "Epoch: 4/20. Validation set: Average loss: 5.3778\n",
      "Train: [0/48048 (0%)]\tLoss: 3.505565\n",
      "Train: [12800/48048 (27%)]\tLoss: 3.970951\n",
      "Train: [25600/48048 (53%)]\tLoss: 3.900489\n",
      "Train: [38400/48048 (80%)]\tLoss: 3.655735\n",
      "Epoch: 5/20. Train set: Average loss: 3.7785\n",
      "Epoch: 5/20. Validation set: Average loss: 4.0845\n",
      "Train: [0/48048 (0%)]\tLoss: 5.215219\n",
      "Train: [12800/48048 (27%)]\tLoss: 3.179137\n",
      "Train: [25600/48048 (53%)]\tLoss: 3.047766\n",
      "Train: [38400/48048 (80%)]\tLoss: 2.962906\n",
      "Epoch: 6/20. Train set: Average loss: 2.9855\n",
      "Epoch: 6/20. Validation set: Average loss: 3.3106\n",
      "Train: [0/48048 (0%)]\tLoss: 3.122913\n",
      "Train: [12800/48048 (27%)]\tLoss: 2.573502\n",
      "Train: [25600/48048 (53%)]\tLoss: 2.571091\n",
      "Train: [38400/48048 (80%)]\tLoss: 2.362915\n",
      "Epoch: 7/20. Train set: Average loss: 2.4655\n",
      "Epoch: 7/20. Validation set: Average loss: 2.8297\n",
      "Train: [0/48048 (0%)]\tLoss: 2.254118\n",
      "Train: [12800/48048 (27%)]\tLoss: 2.168560\n",
      "Train: [25600/48048 (53%)]\tLoss: 2.060243\n",
      "Train: [38400/48048 (80%)]\tLoss: 2.038479\n",
      "Epoch: 8/20. Train set: Average loss: 2.0774\n",
      "Epoch: 8/20. Validation set: Average loss: 2.4737\n",
      "Train: [0/48048 (0%)]\tLoss: 3.139806\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.987310\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.923963\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.879128\n",
      "Epoch: 9/20. Train set: Average loss: 1.9228\n",
      "Epoch: 9/20. Validation set: Average loss: 2.2632\n",
      "Train: [0/48048 (0%)]\tLoss: 2.468990\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.701122\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.601910\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.636114\n",
      "Epoch: 10/20. Train set: Average loss: 1.6596\n",
      "Epoch: 10/20. Validation set: Average loss: 2.1218\n",
      "Train: [0/48048 (0%)]\tLoss: 1.519835\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.792583\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.593051\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.435185\n",
      "Epoch: 11/20. Train set: Average loss: 1.5868\n",
      "Epoch: 11/20. Validation set: Average loss: 1.9986\n",
      "Train: [0/48048 (0%)]\tLoss: 1.471784\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.403788\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.472489\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.382300\n",
      "Epoch: 12/20. Train set: Average loss: 1.3893\n",
      "Epoch: 12/20. Validation set: Average loss: 1.9119\n",
      "Train: [0/48048 (0%)]\tLoss: 0.704320\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.412105\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.234061\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.430451\n",
      "Epoch: 13/20. Train set: Average loss: 1.3703\n",
      "Epoch: 13/20. Validation set: Average loss: 1.8445\n",
      "Train: [0/48048 (0%)]\tLoss: 0.966634\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.300180\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.280193\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.194213\n",
      "Epoch: 14/20. Train set: Average loss: 1.2616\n",
      "Epoch: 14/20. Validation set: Average loss: 1.7902\n",
      "Train: [0/48048 (0%)]\tLoss: 0.962736\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.213516\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.214269\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.286245\n",
      "Epoch: 15/20. Train set: Average loss: 1.2488\n",
      "Epoch: 15/20. Validation set: Average loss: 1.7126\n",
      "Train: [0/48048 (0%)]\tLoss: 0.939446\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.105859\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.248094\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.089018\n",
      "Epoch: 16/20. Train set: Average loss: 1.1660\n",
      "Epoch: 16/20. Validation set: Average loss: 1.6350\n",
      "Train: [0/48048 (0%)]\tLoss: 0.983107\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.288725\n",
      "Train: [25600/48048 (53%)]\tLoss: 0.990075\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.169647\n",
      "Epoch: 17/20. Train set: Average loss: 1.1421\n",
      "Epoch: 17/20. Validation set: Average loss: 1.5343\n",
      "Train: [0/48048 (0%)]\tLoss: 1.259644\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.010682\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.033272\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.052738\n",
      "Epoch: 18/20. Train set: Average loss: 1.0325\n",
      "Epoch: 18/20. Validation set: Average loss: 1.4683\n",
      "Train: [0/48048 (0%)]\tLoss: 0.556157\n",
      "Train: [12800/48048 (27%)]\tLoss: 0.963152\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.051058\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.121770\n",
      "Epoch: 19/20. Train set: Average loss: 1.0348\n",
      "Epoch: 19/20. Validation set: Average loss: 1.4428\n",
      "Train: [0/48048 (0%)]\tLoss: 0.523857\n",
      "Train: [12800/48048 (27%)]\tLoss: 0.935595\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.096651\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.062296\n",
      "Epoch: 20/20. Train set: Average loss: 1.0383\n",
      "Epoch: 20/20. Validation set: Average loss: 1.3998\n",
      "embedding dataset\n",
      "quantizing dataset\n",
      "done quantizing into 626 buckets\n",
      "embedding dataset\n",
      "quantizing dataset\n",
      "done quantizing into 141 buckets\n",
      "initialising model biases\n",
      "done\n",
      "Train: [0/48048 (0%)]\tLoss: 10.953419\n",
      "Train: [12800/48048 (27%)]\tLoss: 16.486493\n",
      "Train: [25600/48048 (53%)]\tLoss: 15.790120\n",
      "Train: [38400/48048 (80%)]\tLoss: 15.689996\n",
      "Epoch: 1/20. Train set: Average loss: 15.5816\n",
      "Epoch: 1/20. Validation set: Average loss: 17.8141\n",
      "Train: [0/48048 (0%)]\tLoss: 14.625729\n",
      "Train: [12800/48048 (27%)]\tLoss: 13.310255\n",
      "Train: [25600/48048 (53%)]\tLoss: 12.603238\n",
      "Train: [38400/48048 (80%)]\tLoss: 11.616507\n",
      "Epoch: 2/20. Train set: Average loss: 11.9701\n",
      "Epoch: 2/20. Validation set: Average loss: 12.6858\n",
      "Train: [0/48048 (0%)]\tLoss: 14.276572\n",
      "Train: [12800/48048 (27%)]\tLoss: 9.278994\n",
      "Train: [25600/48048 (53%)]\tLoss: 8.518031\n",
      "Train: [38400/48048 (80%)]\tLoss: 7.745343\n",
      "Epoch: 3/20. Train set: Average loss: 8.1734\n",
      "Epoch: 3/20. Validation set: Average loss: 8.4679\n",
      "Train: [0/48048 (0%)]\tLoss: 6.955252\n",
      "Train: [12800/48048 (27%)]\tLoss: 6.461036\n",
      "Train: [25600/48048 (53%)]\tLoss: 5.709809\n",
      "Train: [38400/48048 (80%)]\tLoss: 5.274246\n",
      "Epoch: 4/20. Train set: Average loss: 5.6134\n",
      "Epoch: 4/20. Validation set: Average loss: 5.7357\n",
      "Train: [0/48048 (0%)]\tLoss: 5.011267\n",
      "Train: [12800/48048 (27%)]\tLoss: 4.557258\n",
      "Train: [25600/48048 (53%)]\tLoss: 4.073207\n",
      "Train: [38400/48048 (80%)]\tLoss: 4.069498\n",
      "Epoch: 5/20. Train set: Average loss: 4.1639\n",
      "Epoch: 5/20. Validation set: Average loss: 4.4054\n",
      "Train: [0/48048 (0%)]\tLoss: 5.508659\n",
      "Train: [12800/48048 (27%)]\tLoss: 3.634768\n",
      "Train: [25600/48048 (53%)]\tLoss: 3.471690\n",
      "Train: [38400/48048 (80%)]\tLoss: 3.137551\n",
      "Epoch: 6/20. Train set: Average loss: 3.4007\n",
      "Epoch: 6/20. Validation set: Average loss: 3.5725\n",
      "Train: [0/48048 (0%)]\tLoss: 5.741435\n",
      "Train: [12800/48048 (27%)]\tLoss: 2.824024\n",
      "Train: [25600/48048 (53%)]\tLoss: 2.709294\n",
      "Train: [38400/48048 (80%)]\tLoss: 2.416504\n",
      "Epoch: 7/20. Train set: Average loss: 2.6491\n",
      "Epoch: 7/20. Validation set: Average loss: 2.9894\n",
      "Train: [0/48048 (0%)]\tLoss: 2.427670\n",
      "Train: [12800/48048 (27%)]\tLoss: 2.604687\n",
      "Train: [25600/48048 (53%)]\tLoss: 2.253378\n",
      "Train: [38400/48048 (80%)]\tLoss: 2.151792\n",
      "Epoch: 8/20. Train set: Average loss: 2.3316\n",
      "Epoch: 8/20. Validation set: Average loss: 2.5987\n",
      "Train: [0/48048 (0%)]\tLoss: 3.042215\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.998188\n",
      "Train: [25600/48048 (53%)]\tLoss: 2.099438\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.931733\n",
      "Epoch: 9/20. Train set: Average loss: 1.9632\n",
      "Epoch: 9/20. Validation set: Average loss: 2.3060\n",
      "Train: [0/48048 (0%)]\tLoss: 2.682207\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.791351\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.751935\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.824089\n",
      "Epoch: 10/20. Train set: Average loss: 1.7497\n",
      "Epoch: 10/20. Validation set: Average loss: 2.0427\n",
      "Train: [0/48048 (0%)]\tLoss: 1.993390\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.703449\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.640360\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.636210\n",
      "Epoch: 11/20. Train set: Average loss: 1.5848\n",
      "Epoch: 11/20. Validation set: Average loss: 1.8962\n",
      "Train: [0/48048 (0%)]\tLoss: 1.076182\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.556554\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.329051\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.471606\n",
      "Epoch: 12/20. Train set: Average loss: 1.4454\n",
      "Epoch: 12/20. Validation set: Average loss: 1.7954\n",
      "Train: [0/48048 (0%)]\tLoss: 0.597204\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.436798\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.379848\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.326133\n",
      "Epoch: 13/20. Train set: Average loss: 1.3715\n",
      "Epoch: 13/20. Validation set: Average loss: 1.7186\n",
      "Train: [0/48048 (0%)]\tLoss: 0.504904\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.366240\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.370308\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.046601\n",
      "Epoch: 14/20. Train set: Average loss: 1.2626\n",
      "Epoch: 14/20. Validation set: Average loss: 1.6652\n",
      "Train: [0/48048 (0%)]\tLoss: 2.935765\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.287699\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.215208\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.207271\n",
      "Epoch: 15/20. Train set: Average loss: 1.2316\n",
      "Epoch: 15/20. Validation set: Average loss: 1.6191\n",
      "Train: [0/48048 (0%)]\tLoss: 0.548597\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.095917\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.213736\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.287654\n",
      "Epoch: 16/20. Train set: Average loss: 1.1903\n",
      "Epoch: 16/20. Validation set: Average loss: 1.5790\n",
      "Train: [0/48048 (0%)]\tLoss: 0.562002\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.134012\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.062992\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.113789\n",
      "Epoch: 17/20. Train set: Average loss: 1.0893\n",
      "Epoch: 17/20. Validation set: Average loss: 1.5905\n",
      "Train: [0/48048 (0%)]\tLoss: 1.156840\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.148075\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.221380\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.095355\n",
      "Epoch: 18/20. Train set: Average loss: 1.1263\n",
      "Epoch: 18/20. Validation set: Average loss: 1.5740\n",
      "Train: [0/48048 (0%)]\tLoss: 0.702680\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.107262\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.071301\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.167988\n",
      "Epoch: 19/20. Train set: Average loss: 1.1398\n",
      "Epoch: 19/20. Validation set: Average loss: 1.5455\n",
      "Train: [0/48048 (0%)]\tLoss: 2.376566\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.126155\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.150326\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.202629\n",
      "Epoch: 20/20. Train set: Average loss: 1.1472\n",
      "Epoch: 20/20. Validation set: Average loss: 1.5026\n",
      "embedding dataset\n",
      "quantizing dataset\n",
      "done quantizing into 644 buckets\n",
      "embedding dataset\n",
      "quantizing dataset\n",
      "done quantizing into 131 buckets\n",
      "initialising model biases\n",
      "done\n",
      "Train: [0/48048 (0%)]\tLoss: 12.047181\n",
      "Train: [12800/48048 (27%)]\tLoss: 16.400153\n",
      "Train: [25600/48048 (53%)]\tLoss: 15.688603\n",
      "Train: [38400/48048 (80%)]\tLoss: 14.634198\n",
      "Epoch: 1/20. Train set: Average loss: 15.3686\n",
      "Epoch: 1/20. Validation set: Average loss: 17.6573\n",
      "Train: [0/48048 (0%)]\tLoss: 11.651788\n",
      "Train: [12800/48048 (27%)]\tLoss: 13.279189\n",
      "Train: [25600/48048 (53%)]\tLoss: 12.431997\n",
      "Train: [38400/48048 (80%)]\tLoss: 11.637009\n",
      "Epoch: 2/20. Train set: Average loss: 11.9923\n",
      "Epoch: 2/20. Validation set: Average loss: 12.3406\n",
      "Train: [0/48048 (0%)]\tLoss: 12.568079\n",
      "Train: [12800/48048 (27%)]\tLoss: 9.480091\n",
      "Train: [25600/48048 (53%)]\tLoss: 8.154442\n",
      "Train: [38400/48048 (80%)]\tLoss: 7.083445\n",
      "Epoch: 3/20. Train set: Average loss: 7.9529\n",
      "Epoch: 3/20. Validation set: Average loss: 7.8689\n",
      "Train: [0/48048 (0%)]\tLoss: 4.324519\n",
      "Train: [12800/48048 (27%)]\tLoss: 6.134171\n",
      "Train: [25600/48048 (53%)]\tLoss: 5.493876\n",
      "Train: [38400/48048 (80%)]\tLoss: 5.197288\n",
      "Epoch: 4/20. Train set: Average loss: 5.4508\n",
      "Epoch: 4/20. Validation set: Average loss: 5.6134\n",
      "Train: [0/48048 (0%)]\tLoss: 5.921659\n",
      "Train: [12800/48048 (27%)]\tLoss: 4.480745\n",
      "Train: [25600/48048 (53%)]\tLoss: 4.118187\n",
      "Train: [38400/48048 (80%)]\tLoss: 4.126002\n",
      "Epoch: 5/20. Train set: Average loss: 4.0933\n",
      "Epoch: 5/20. Validation set: Average loss: 4.2455\n",
      "Train: [0/48048 (0%)]\tLoss: 3.146237\n",
      "Train: [12800/48048 (27%)]\tLoss: 3.537239\n",
      "Train: [25600/48048 (53%)]\tLoss: 3.314880\n",
      "Train: [38400/48048 (80%)]\tLoss: 3.203240\n",
      "Epoch: 6/20. Train set: Average loss: 3.2456\n",
      "Epoch: 6/20. Validation set: Average loss: 3.4044\n",
      "Train: [0/48048 (0%)]\tLoss: 3.844330\n",
      "Train: [12800/48048 (27%)]\tLoss: 2.810955\n",
      "Train: [25600/48048 (53%)]\tLoss: 2.736599\n",
      "Train: [38400/48048 (80%)]\tLoss: 2.625968\n",
      "Epoch: 7/20. Train set: Average loss: 2.6888\n",
      "Epoch: 7/20. Validation set: Average loss: 2.8986\n",
      "Train: [0/48048 (0%)]\tLoss: 1.895123\n",
      "Train: [12800/48048 (27%)]\tLoss: 2.443597\n",
      "Train: [25600/48048 (53%)]\tLoss: 2.083436\n",
      "Train: [38400/48048 (80%)]\tLoss: 2.170445\n",
      "Epoch: 8/20. Train set: Average loss: 2.1932\n",
      "Epoch: 8/20. Validation set: Average loss: 2.4991\n",
      "Train: [0/48048 (0%)]\tLoss: 1.803288\n",
      "Train: [12800/48048 (27%)]\tLoss: 2.195310\n",
      "Train: [25600/48048 (53%)]\tLoss: 2.214954\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.789409\n",
      "Epoch: 9/20. Train set: Average loss: 2.0478\n",
      "Epoch: 9/20. Validation set: Average loss: 2.2211\n",
      "Train: [0/48048 (0%)]\tLoss: 2.459948\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.755092\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.672390\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.659701\n",
      "Epoch: 10/20. Train set: Average loss: 1.7004\n",
      "Epoch: 10/20. Validation set: Average loss: 2.0791\n",
      "Train: [0/48048 (0%)]\tLoss: 1.296381\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.610769\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.508417\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.604530\n",
      "Epoch: 11/20. Train set: Average loss: 1.6010\n",
      "Epoch: 11/20. Validation set: Average loss: 1.9787\n",
      "Train: [0/48048 (0%)]\tLoss: 1.940173\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.540135\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.470022\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.455139\n",
      "Epoch: 12/20. Train set: Average loss: 1.4478\n",
      "Epoch: 12/20. Validation set: Average loss: 1.8822\n",
      "Train: [0/48048 (0%)]\tLoss: 1.283685\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.358941\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.392168\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.389643\n",
      "Epoch: 13/20. Train set: Average loss: 1.3559\n",
      "Epoch: 13/20. Validation set: Average loss: 1.8009\n",
      "Train: [0/48048 (0%)]\tLoss: 1.909340\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.253699\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.416571\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.273389\n",
      "Epoch: 14/20. Train set: Average loss: 1.2944\n",
      "Epoch: 14/20. Validation set: Average loss: 1.7615\n",
      "Train: [0/48048 (0%)]\tLoss: 3.453010\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.276289\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.378841\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.067759\n",
      "Epoch: 15/20. Train set: Average loss: 1.2389\n",
      "Epoch: 15/20. Validation set: Average loss: 1.7282\n",
      "Train: [0/48048 (0%)]\tLoss: 1.583247\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.186285\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.190553\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.261148\n",
      "Epoch: 16/20. Train set: Average loss: 1.2067\n",
      "Epoch: 16/20. Validation set: Average loss: 1.6909\n",
      "Train: [0/48048 (0%)]\tLoss: 0.629920\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.199703\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.290413\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.114725\n",
      "Epoch: 17/20. Train set: Average loss: 1.1969\n",
      "Epoch: 17/20. Validation set: Average loss: 1.6658\n",
      "Train: [0/48048 (0%)]\tLoss: 3.064640\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.143379\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.081448\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.073919\n",
      "Epoch: 18/20. Train set: Average loss: 1.0885\n",
      "Epoch: 18/20. Validation set: Average loss: 1.6270\n",
      "Train: [0/48048 (0%)]\tLoss: 0.622033\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.165677\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.124150\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.074083\n",
      "Epoch: 19/20. Train set: Average loss: 1.1081\n",
      "Epoch: 19/20. Validation set: Average loss: 1.5585\n",
      "Train: [0/48048 (0%)]\tLoss: 0.531904\n",
      "Train: [12800/48048 (27%)]\tLoss: 1.233365\n",
      "Train: [25600/48048 (53%)]\tLoss: 1.048142\n",
      "Train: [38400/48048 (80%)]\tLoss: 1.084213\n",
      "Epoch: 20/20. Train set: Average loss: 1.0713\n",
      "Epoch: 20/20. Validation set: Average loss: 1.5438\n",
      "embedding dataset\n",
      "quantizing dataset\n",
      "done quantizing into 591 buckets\n",
      "embedding dataset\n",
      "quantizing dataset\n",
      "done quantizing into 134 buckets\n",
      "initialising model biases\n",
      "done\n",
      "Train: [0/48048 (0%)]\tLoss: 22.586496\n",
      "Train: [12800/48048 (27%)]\tLoss: 15.946078\n",
      "Train: [25600/48048 (53%)]\tLoss: 15.960676\n",
      "Train: [38400/48048 (80%)]\tLoss: 15.048069\n",
      "Epoch: 1/20. Train set: Average loss: 15.3249\n",
      "Epoch: 1/20. Validation set: Average loss: 17.9136\n",
      "Train: [0/48048 (0%)]\tLoss: 24.037752\n",
      "Train: [12800/48048 (27%)]\tLoss: 13.854439\n",
      "Train: [25600/48048 (53%)]\tLoss: 12.217508\n",
      "Train: [38400/48048 (80%)]\tLoss: 11.498535\n",
      "Epoch: 2/20. Train set: Average loss: 12.1708\n",
      "Epoch: 2/20. Validation set: Average loss: 12.9011\n",
      "Train: [0/48048 (0%)]\tLoss: 11.470901\n",
      "Train: [12800/48048 (27%)]\tLoss: 9.502416\n",
      "Train: [25600/48048 (53%)]\tLoss: 8.829612\n",
      "Train: [38400/48048 (80%)]\tLoss: 7.233676\n",
      "Epoch: 3/20. Train set: Average loss: 8.1583\n",
      "Epoch: 3/20. Validation set: Average loss: 8.2579\n",
      "Train: [0/48048 (0%)]\tLoss: 5.959527\n",
      "Train: [12800/48048 (27%)]\tLoss: 6.137072\n",
      "Train: [25600/48048 (53%)]\tLoss: 5.648810\n",
      "Train: [38400/48048 (80%)]\tLoss: 5.153930\n",
      "Epoch: 4/20. Train set: Average loss: 5.5383\n",
      "Epoch: 4/20. Validation set: Average loss: 5.8205\n",
      "Train: [0/48048 (0%)]\tLoss: 3.840177\n",
      "Train: [12800/48048 (27%)]\tLoss: 4.610791\n",
      "Train: [25600/48048 (53%)]\tLoss: 4.065465\n",
      "Train: [38400/48048 (80%)]\tLoss: 3.951185\n",
      "Epoch: 5/20. Train set: Average loss: 4.1498\n",
      "Epoch: 5/20. Validation set: Average loss: 4.2865\n",
      "Train: [0/48048 (0%)]\tLoss: 1.504585\n",
      "Train: [12800/48048 (27%)]\tLoss: 3.412674\n",
      "Train: [25600/48048 (53%)]\tLoss: 3.206138\n",
      "Train: [38400/48048 (80%)]\tLoss: 3.012063\n",
      "Epoch: 6/20. Train set: Average loss: 3.1463\n",
      "Epoch: 6/20. Validation set: Average loss: 3.4163\n",
      "Train: [0/48048 (0%)]\tLoss: 2.309701\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-b37adcff1cd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_RECALL_CAND\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#run the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplet_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtriplet_test_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOG_INT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m#measure recall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtrain_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_recall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasure_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtriplet_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtriplet_test_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/University/2019/Thesis/code/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(train_loader, val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, metrics, start_epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Train stage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter_train_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter_train_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Epoch: {}/{}. Train set: Average loss: {:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/University/2019/Thesis/code/trainer.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(train_loader, model, loss_fn, optimizer, cuda, log_interval, metrics, writer, writer_train_index)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/University/2019/Thesis/code/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, x3)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0moutput3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/University/2019/Thesis/code/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/University/2019/Thesis/code/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/University/2019/Thesis/code/networks.py\u001b[0m in \u001b[0;36manchor_dist\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#perform transpose within each batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.unsqueeze(-1) #ensure return shape is batch x output x 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "#     for P_STRONG_NEG in P_STRONG_NEGS: #itertools.product(*hyperparams):\n",
    "    #setup datasets\n",
    "    triplet_train_dataset = TripletAudio(True, K, MAX_CLOSE_NEG, P_STRONG_NEG)\n",
    "    triplet_test_dataset = TripletAudio(False, K, MAX_CLOSE_NEG, P_STRONG_NEG)\n",
    "    triplet_train_loader = torch.utils.data.DataLoader(triplet_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    triplet_test_loader = torch.utils.data.DataLoader(triplet_test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    #define model \n",
    "    anchor_net = AnchorNet(triplet_train_dataset.get_dataset(), INPUT_D, OUTPUT_D)\n",
    "    embedding_net = EmbeddingNet(anchor_net)\n",
    "    model = TripletNet(embedding_net)\n",
    "    loss_fn = TripletLoss(MARGIN)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1, last_epoch=-1)\n",
    "    recall = Recall(N_RECALL_CAND, K)\n",
    "    #run the model\n",
    "    train_loss, val_loss = fit(triplet_train_loader, triplet_test_loader, model, loss_fn, optimizer, scheduler, N_EPOCHS, {}, LOG_INT)\n",
    "    #measure recall\n",
    "    train_recall, val_recall = measure_recall([triplet_train_dataset, triplet_test_dataset])\n",
    "    #write to tensorboard\n",
    "    with SummaryWriter() as w:\n",
    "        w.add_hparams(\n",
    "            {'LR': LEARNING_RATE, 'BSIZE': BATCH_SIZE, 'N_RECALL_S': N_RECALL_SAMPLES, 'N_RECALL_CAND': N_RECALL_CAND,\n",
    "                 'CLOSE_NEG': MAX_CLOSE_NEG, 'P_STRONG_NEG': P_STRONG_NEG, 'OUTPUT_D': OUTPUT_D},\n",
    "            {'TRAIN_L': train_loss, 'VAL_L': val_loss, 'TRAIN_RECALL': train_recall, 'VAL_RECALL': val_recall})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#prepare data \n",
    "# %load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from datasets import AudioTrainDataset, AudioTestDataset\n",
    "from datasets import BalancedBatchSampler\n",
    "\n",
    "K = 5\n",
    "train_dataset = AudioTrainDataset(K)\n",
    "test_dataset = AudioTestDataset(K)\n",
    "\n",
    "train_batch_sampler = BalancedBatchSampler(train_dataset)\n",
    "test_batch_sampler = BalancedBatchSampler(test_dataset)\n",
    "\n",
    "online_train_loader = torch.utils.data.DataLoader(train_dataset, batch_sampler=train_batch_sampler)\n",
    "online_test_loader = torch.utils.data.DataLoader(test_dataset, batch_sampler=test_batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Set up the network and training parameters\n",
    "from networks import EmbeddingNet, AnchorNet\n",
    "from losses import OnlineTripletLoss\n",
    "from utils import SemihardNegativeTripletSelector, HardestNegativeTripletSelector\n",
    "from metrics import AverageNonzeroTripletsMetric\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "INPUT_D, OUTPUT_D = 192, 128\n",
    "MARGIN, LEARNING_RATE, N_EPOCHS, LOG_INT = 0.5, 1e-3, 5, 50\n",
    "\n",
    "#define model\n",
    "anchor_net = AnchorNet(train_dataset.data, INPUT_D, OUTPUT_D)\n",
    "model = EmbeddingNet(anchor_net)\n",
    "loss_fn = OnlineTripletLoss(MARGIN, SemihardNegativeTripletSelector(MARGIN, train_dataset.KNN))\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#run model\n",
    "from trainer import fit\n",
    "fit(online_train_loader, online_test_loader, model, loss_fn, optimizer, scheduler, N_EPOCHS, {}, LOG_INT, metrics=[AverageNonzeroTripletsMetric()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis] *",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "415px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#prepare data \n",
    "# %load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from recall import Recall\n",
    "from datasets import TripletAudio\n",
    "\n",
    "K, MAX_CLOSE_NEG, MAX_FAR_NEG = 5, 15, 15\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "triplet_train_dataset = TripletAudio(True, K, MAX_CLOSE_NEG, MAX_FAR_NEG)\n",
    "triplet_test_dataset = TripletAudio(False, K, MAX_CLOSE_NEG, MAX_FAR_NEG)\n",
    "triplet_train_loader = torch.utils.data.DataLoader(triplet_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "triplet_test_loader = torch.utils.data.DataLoader(triplet_test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialising model biases\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Set up the network and training parameters\n",
    "from networks import AnchorNet, EmbeddingNet, TripletNet\n",
    "from losses import TripletLoss\n",
    "import torch.optim as optim\n",
    "from recall import Recall\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "INPUT_D, OUTPUT_D = 192, 128\n",
    "MARGIN, LEARNING_RATE, N_EPOCHS, LOG_INT, RECALL_NUM_CAND = 0.5, 1e-3, 15, 100, 25\n",
    "\n",
    "#define model\n",
    "anchor_net = AnchorNet(triplet_train_dataset.get_dataset(), INPUT_D, OUTPUT_D)\n",
    "embedding_net = EmbeddingNet(anchor_net)\n",
    "model = TripletNet(embedding_net)\n",
    "\n",
    "loss_fn = TripletLoss(MARGIN)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "\n",
    "recall = Recall(RECALL_NUM_CAND, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/48048 (0%)]\tLoss: 5.203338\n",
      "Train: [12800/48048 (27%)]\tLoss: 0.719875\n",
      "Train: [25600/48048 (53%)]\tLoss: 0.459662\n",
      "Train: [38400/48048 (80%)]\tLoss: 0.418596\n",
      "Epoch: 1/15. Train set: Average loss: 0.5126\n",
      "Epoch: 1/15. Validation set: Average loss: 0.3728\n",
      "Train: [0/48048 (0%)]\tLoss: 0.306808\n",
      "Train: [12800/48048 (27%)]\tLoss: 0.338364\n",
      "Train: [25600/48048 (53%)]\tLoss: 0.299925\n",
      "Train: [38400/48048 (80%)]\tLoss: 0.279342\n",
      "Epoch: 2/15. Train set: Average loss: 0.2985\n",
      "Epoch: 2/15. Validation set: Average loss: 0.2699\n",
      "Train: [0/48048 (0%)]\tLoss: 0.218594\n",
      "Train: [12800/48048 (27%)]\tLoss: 0.257411\n",
      "Train: [25600/48048 (53%)]\tLoss: 0.249688\n",
      "Train: [38400/48048 (80%)]\tLoss: 0.244688\n",
      "Epoch: 3/15. Train set: Average loss: 0.2495\n",
      "Epoch: 3/15. Validation set: Average loss: 0.2530\n",
      "Train: [0/48048 (0%)]\tLoss: 0.253314\n",
      "Train: [12800/48048 (27%)]\tLoss: 0.235932\n",
      "Train: [25600/48048 (53%)]\tLoss: 0.234376\n",
      "Train: [38400/48048 (80%)]\tLoss: 0.232255\n",
      "Epoch: 4/15. Train set: Average loss: 0.2318\n",
      "Epoch: 4/15. Validation set: Average loss: 0.2187\n",
      "Train: [0/48048 (0%)]\tLoss: 0.190955\n",
      "Train: [12800/48048 (27%)]\tLoss: 0.219635\n",
      "Train: [25600/48048 (53%)]\tLoss: 0.223093\n",
      "Train: [38400/48048 (80%)]\tLoss: 0.218127\n",
      "Epoch: 5/15. Train set: Average loss: 0.2177\n",
      "Epoch: 5/15. Validation set: Average loss: 0.2079\n",
      "Train: [0/48048 (0%)]\tLoss: 0.213277\n",
      "Train: [12800/48048 (27%)]\tLoss: 0.208455\n",
      "Train: [25600/48048 (53%)]\tLoss: 0.206281\n",
      "Train: [38400/48048 (80%)]\tLoss: 0.210230\n",
      "Epoch: 6/15. Train set: Average loss: 0.2095\n",
      "Epoch: 6/15. Validation set: Average loss: 0.2105\n",
      "Train: [0/48048 (0%)]\tLoss: 0.184857\n",
      "Train: [12800/48048 (27%)]\tLoss: 0.208694\n",
      "Train: [25600/48048 (53%)]\tLoss: 0.206759\n",
      "Train: [38400/48048 (80%)]\tLoss: 0.205065\n",
      "Epoch: 7/15. Train set: Average loss: 0.2059\n",
      "Epoch: 7/15. Validation set: Average loss: 0.1944\n",
      "Train: [0/48048 (0%)]\tLoss: 0.211071\n",
      "Train: [12800/48048 (27%)]\tLoss: 0.203133\n",
      "Train: [25600/48048 (53%)]\tLoss: 0.201671\n",
      "Train: [38400/48048 (80%)]\tLoss: 0.197670\n",
      "Epoch: 8/15. Train set: Average loss: 0.2003\n",
      "Epoch: 8/15. Validation set: Average loss: 0.1911\n",
      "Train: [0/48048 (0%)]\tLoss: 0.181324\n",
      "Train: [12800/48048 (27%)]\tLoss: 0.198753\n",
      "Train: [25600/48048 (53%)]\tLoss: 0.197258\n",
      "Train: [38400/48048 (80%)]\tLoss: 0.197234\n",
      "Epoch: 9/15. Train set: Average loss: 0.1982\n",
      "Epoch: 9/15. Validation set: Average loss: 0.1892\n",
      "Train: [0/48048 (0%)]\tLoss: 0.165601\n",
      "Train: [12800/48048 (27%)]\tLoss: 0.195100\n",
      "Train: [25600/48048 (53%)]\tLoss: 0.194210\n",
      "Train: [38400/48048 (80%)]\tLoss: 0.197166\n",
      "Epoch: 10/15. Train set: Average loss: 0.1963\n",
      "Epoch: 10/15. Validation set: Average loss: 0.1880\n",
      "Train: [0/48048 (0%)]\tLoss: 0.172104\n",
      "Train: [12800/48048 (27%)]\tLoss: 0.192722\n",
      "Train: [25600/48048 (53%)]\tLoss: 0.201628\n",
      "Train: [38400/48048 (80%)]\tLoss: 0.202333\n",
      "Epoch: 11/15. Train set: Average loss: 0.1986\n",
      "Epoch: 11/15. Validation set: Average loss: 0.1877\n",
      "Train: [0/48048 (0%)]\tLoss: 0.163881\n",
      "Train: [12800/48048 (27%)]\tLoss: 0.200455\n",
      "Train: [25600/48048 (53%)]\tLoss: 0.194262\n",
      "Train: [38400/48048 (80%)]\tLoss: 0.194515\n",
      "Epoch: 12/15. Train set: Average loss: 0.1954\n",
      "Epoch: 12/15. Validation set: Average loss: 0.1866\n",
      "Train: [0/48048 (0%)]\tLoss: 0.184449\n",
      "Train: [12800/48048 (27%)]\tLoss: 0.198251\n",
      "Train: [25600/48048 (53%)]\tLoss: 0.192510\n",
      "Train: [38400/48048 (80%)]\tLoss: 0.193516\n",
      "Epoch: 13/15. Train set: Average loss: 0.1948\n",
      "Epoch: 13/15. Validation set: Average loss: 0.1864\n",
      "Train: [0/48048 (0%)]\tLoss: 0.238241\n",
      "Train: [12800/48048 (27%)]\tLoss: 0.193857\n",
      "Train: [25600/48048 (53%)]\tLoss: 0.192082\n",
      "Train: [38400/48048 (80%)]\tLoss: 0.198007\n",
      "Epoch: 14/15. Train set: Average loss: 0.1935\n",
      "Epoch: 14/15. Validation set: Average loss: 0.1857\n",
      "Train: [0/48048 (0%)]\tLoss: 0.184399\n",
      "Train: [12800/48048 (27%)]\tLoss: 0.193815\n",
      "Train: [25600/48048 (53%)]\tLoss: 0.192617\n",
      "Train: [38400/48048 (80%)]\tLoss: 0.191760\n",
      "Epoch: 15/15. Train set: Average loss: 0.1929\n",
      "Epoch: 15/15. Validation set: Average loss: 0.1848\n"
     ]
    }
   ],
   "source": [
    "#run the model\n",
    "from trainer import fit\n",
    "fit(triplet_train_loader, triplet_test_loader, model, loss_fn, optimizer, scheduler, N_EPOCHS, {}, LOG_INT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# perform recall on random batch\n",
    "outputs = []\n",
    "for d in (triplet_train_dataset, triplet_test_dataset):\n",
    "    batch_indicies = np.random.choice(list(range(0, d.get_dataset().shape[0])), 500, False)\n",
    "    queries = d.get_dataset()[batch_indicies]\n",
    "    true_knns = d.get_knn().iloc[batch_indicies, :]\n",
    "    outputs.append(recall.calculate(d.get_dataset(), model.embedding_net, queries, true_knns, False))\n",
    "print(np.mean(outputs[0]), np.mean(outputs[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#prepare data \n",
    "# %load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from datasets import AudioTrainDataset, AudioTestDataset\n",
    "from datasets import BalancedBatchSampler\n",
    "\n",
    "K = 5\n",
    "train_dataset = AudioTrainDataset(K)\n",
    "test_dataset = AudioTestDataset(K)\n",
    "\n",
    "train_batch_sampler = BalancedBatchSampler(train_dataset)\n",
    "test_batch_sampler = BalancedBatchSampler(test_dataset)\n",
    "\n",
    "online_train_loader = torch.utils.data.DataLoader(train_dataset, batch_sampler=train_batch_sampler)\n",
    "online_test_loader = torch.utils.data.DataLoader(test_dataset, batch_sampler=test_batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Set up the network and training parameters\n",
    "from networks import EmbeddingNet, AnchorNet\n",
    "from losses import OnlineTripletLoss\n",
    "from utils import SemihardNegativeTripletSelector, HardestNegativeTripletSelector\n",
    "from metrics import AverageNonzeroTripletsMetric\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "INPUT_D, OUTPUT_D = 192, 128\n",
    "MARGIN, LEARNING_RATE, N_EPOCHS, LOG_INT = 0.5, 1e-3, 5, 50\n",
    "\n",
    "#define model\n",
    "anchor_net = AnchorNet(train_dataset.data, INPUT_D, OUTPUT_D)\n",
    "model = EmbeddingNet(anchor_net)\n",
    "loss_fn = OnlineTripletLoss(MARGIN, SemihardNegativeTripletSelector(MARGIN, train_dataset.KNN))\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from trainer import fit\n",
    "fit(online_train_loader, online_test_loader, model, loss_fn, optimizer, scheduler, N_EPOCHS, {}, LOG_INT, metrics=[AverageNonzeroTripletsMetric()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis] *",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "415px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/llSourcell/pytorch_in_5_minutes/blob/master/demo.py\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "from torch.nn.modules.distance import PairwiseDistance\n",
    "\n",
    "class TripletLoss(Function):\n",
    "    \n",
    "    def __init__(self, alpha):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.pdist  = PairwiseDistance(2)\n",
    "        \n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_dist   = self.pdist.forward(anchor, positive).pow(2)\n",
    "        neg_dist   = self.pdist.forward(anchor, negative).pow(2)\n",
    "        hinge_dist = torch.clamp(self.alpha + pos_dist - neg_dist, min = 0.0)\n",
    "        loss       = torch.mean(hinge_dist)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.3 s, sys: 8.3 s, total: 25.6 s\n",
      "Wall time: 26.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#read in relevant data\n",
    "trainData = torch.from_numpy(np.loadtxt('data/trainData.txt', dtype=np.float32))\n",
    "queryData = torch.from_numpy(np.loadtxt('data/queryData.txt', dtype=np.float32))\n",
    "df =  pd.read_pickle(\"./data/KNN.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE is batch size; INPUT_D is input dimension; OUTPUT_D is output dimension; \n",
    "BATCH_SIZE, INPUT_D, HIDDEN_D, OUTPUT_D = 100, 192, 128, 128\n",
    "ALPHA = 0.5\n",
    "LEARNING_RATE = 1\n",
    "K = 5\n",
    "\n",
    "def init_model():\n",
    "    print(\"--- Initialising Model Params --- \")\n",
    "    # Create random Tensor for trainable features, and wrap them in Variables.\n",
    "    # requires_grad=True indicates that we want to compute gradients wrt these Variables during the backward pass.\n",
    "    anchors = Variable(torch.randn(OUTPUT_D, INPUT_D).type(torch.FloatTensor), requires_grad=True)\n",
    "    # weights = Variable(torch.randn(HIDDEN_D, OUTPUT_D).type(torch.FloatTensor), requires_grad=True)\n",
    "\n",
    "    # set b0 to be mean value\n",
    "    aggregate = torch.zeros(OUTPUT_D)\n",
    "    for point in queryData:\n",
    "        w0 = torch.norm(point.t() - anchors, 2, 1)\n",
    "        aggregate += w0\n",
    "\n",
    "    biases = Variable((aggregate/queryData.shape[0]).reshape(-1, 1), requires_grad=True)\n",
    "    print(\"--- Done. Begining training ---\")\n",
    "    return anchors, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTripplet(index):\n",
    "    point = queryData[index].reshape(-1, 1)\n",
    "    pos = trainData[df.iloc[index].KNN[randint(0,K)]].reshape(-1, 1)\n",
    "    neg = trainData[df.iloc[index].KNN[randint(K, len(df)-1)]].reshape(-1, 1)\n",
    "    return point, pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "def forward_pass(query):\n",
    "    return sigmoid(torch.norm(query.t() - anchors, 2, 1).reshape(-1, 1) - biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(41.4934)\n",
      "1 tensor(46.4123)\n",
      "2 tensor(41.4779)\n",
      "3 tensor(46.9142)\n",
      "4 tensor(36.1964)\n",
      "5 tensor(48.4893)\n",
      "6 tensor(44.7107)\n",
      "7 tensor(43.6143)\n",
      "8 tensor(39.9611)\n",
      "9 tensor(40.5532)\n",
      "10 tensor(37.3945)\n",
      "11 tensor(38.8403)\n",
      "12 tensor(44.3418)\n",
      "13 tensor(35.8196)\n",
      "14 tensor(43.3604)\n",
      "15 tensor(44.6226)\n",
      "16 tensor(41.1356)\n",
      "17 tensor(44.8081)\n",
      "18 tensor(43.1640)\n",
      "19 tensor(48.7209)\n",
      "20 tensor(40.4168)\n",
      "21 tensor(37.3136)\n",
      "22 tensor(42.7325)\n",
      "23 tensor(42.7834)\n",
      "24 tensor(42.8964)\n",
      "25 tensor(43.2495)\n",
      "26 tensor(40.1771)\n",
      "27 tensor(45.3841)\n",
      "28 tensor(42.8846)\n",
      "29 tensor(40.0212)\n",
      "30 tensor(40.4052)\n",
      "31 tensor(38.5106)\n",
      "32 tensor(44.9346)\n",
      "33 tensor(35.2529)\n",
      "34 tensor(43.5309)\n",
      "35 tensor(42.1153)\n",
      "36 tensor(44.6548)\n",
      "37 tensor(35.9885)\n",
      "38 tensor(41.5562)\n",
      "39 tensor(41.4608)\n",
      "40 tensor(39.7521)\n",
      "41 tensor(39.3504)\n",
      "42 tensor(40.2714)\n",
      "43 tensor(42.0676)\n",
      "44 tensor(33.2751)\n",
      "45 tensor(36.6382)\n",
      "46 tensor(35.3337)\n",
      "47 tensor(40.9315)\n",
      "48 tensor(32.6623)\n",
      "49 tensor(40.0415)\n",
      "50 tensor(37.0852)\n",
      "51 tensor(42.2910)\n",
      "52 tensor(35.8593)\n",
      "53 tensor(40.4413)\n",
      "54 tensor(44.6768)\n",
      "55 tensor(34.5074)\n",
      "56 tensor(37.5948)\n",
      "57 tensor(41.9958)\n",
      "58 tensor(31.9343)\n",
      "59 tensor(34.1634)\n",
      "60 tensor(36.1264)\n",
      "61 tensor(38.8577)\n",
      "62 tensor(33.9535)\n",
      "63 tensor(43.1605)\n",
      "64 tensor(38.1502)\n",
      "65 tensor(41.1211)\n",
      "66 tensor(35.6837)\n",
      "67 tensor(37.7389)\n",
      "68 tensor(36.2715)\n",
      "69 tensor(34.1041)\n",
      "70 tensor(33.8263)\n",
      "71 tensor(37.2715)\n",
      "72 tensor(35.4178)\n",
      "73 tensor(36.8111)\n",
      "74 tensor(41.3247)\n",
      "75 tensor(41.9442)\n",
      "76 tensor(38.2328)\n",
      "77 tensor(37.6958)\n",
      "78 tensor(32.7293)\n",
      "79 tensor(38.7153)\n",
      "80 tensor(34.9807)\n",
      "81 tensor(36.3427)\n",
      "82 tensor(34.4353)\n",
      "83 tensor(36.8050)\n",
      "84 tensor(33.2771)\n",
      "85 tensor(36.5941)\n",
      "86 tensor(33.9592)\n",
      "87 tensor(39.9515)\n",
      "88 tensor(36.4182)\n",
      "89 tensor(39.1218)\n",
      "90 tensor(36.1677)\n",
      "91 tensor(39.0403)\n",
      "92 tensor(37.6834)\n",
      "93 tensor(30.1366)\n",
      "94 tensor(35.0241)\n",
      "95 tensor(41.8720)\n",
      "96 tensor(34.7410)\n",
      "97 tensor(36.8672)\n",
      "98 tensor(34.7007)\n",
      "99 tensor(36.0563)\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "anchors, biases = init_model()\n",
    "\n",
    "for epoch in range(100):\n",
    "    \n",
    "    #generate batch and compute collective loss for batch\n",
    "    batch_indicies = np.random.choice(queryData.shape[0], BATCH_SIZE, replace=False)\n",
    "    loss = 0\n",
    "    for index in batch_indicies:\n",
    "        query, pos, neg = generateTripplet(1)\n",
    "        queryMapped, posMapped, negMapped = [forward_pass(x) for x in [query, pos, neg]]\n",
    "        triplet_loss = TripletLoss(ALPHA).forward(queryMapped, posMapped, negMapped)\n",
    "        loss += triplet_loss\n",
    "    \n",
    "    print(epoch, loss.data)\n",
    "\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    # Update params using gradient descent\n",
    "    biases.data -= LEARNING_RATE * biases.grad.data\n",
    "    anchors.data -= LEARNING_RATE * anchors.grad.data\n",
    "\n",
    "    # Manually zero the gradients \n",
    "    biases.grad.data.zero_()\n",
    "    anchors.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.7731e-01],\n",
       "        [-9.8997e-01],\n",
       "        [-9.9090e-01],\n",
       "        [-9.8967e-01],\n",
       "        [-9.9262e-01],\n",
       "        [-8.8068e-01],\n",
       "        [-9.9247e-01],\n",
       "        [-8.0227e-01],\n",
       "        [-9.4777e-01],\n",
       "        [-9.8801e-01],\n",
       "        [-8.6084e-01],\n",
       "        [-9.9064e-01],\n",
       "        [-8.1740e-01],\n",
       "        [-9.7572e-01],\n",
       "        [-8.5580e-01],\n",
       "        [-9.6548e-01],\n",
       "        [-9.8604e-01],\n",
       "        [-9.8229e-01],\n",
       "        [-7.0966e-01],\n",
       "        [-9.8856e-01],\n",
       "        [-8.3321e-01],\n",
       "        [-7.5851e-01],\n",
       "        [-9.9034e-01],\n",
       "        [-8.9640e-01],\n",
       "        [-7.1946e-01],\n",
       "        [-9.7243e-01],\n",
       "        [-9.5354e-01],\n",
       "        [-9.9274e-01],\n",
       "        [ 9.6548e-01],\n",
       "        [-9.7705e-01],\n",
       "        [-9.9076e-01],\n",
       "        [-7.7688e-01],\n",
       "        [-9.8993e-01],\n",
       "        [-9.8569e-01],\n",
       "        [-9.1570e-01],\n",
       "        [-1.3076e-03],\n",
       "        [-9.0260e-01],\n",
       "        [-9.0607e-01],\n",
       "        [-9.8849e-01],\n",
       "        [ 9.9072e-05],\n",
       "        [-5.2665e-06],\n",
       "        [-9.7986e-01],\n",
       "        [-9.8623e-01],\n",
       "        [-9.8565e-01],\n",
       "        [-9.6748e-01],\n",
       "        [-9.7801e-01],\n",
       "        [-9.8864e-01],\n",
       "        [-9.9235e-01],\n",
       "        [-9.3233e-01],\n",
       "        [-8.8290e-01],\n",
       "        [-9.8265e-01],\n",
       "        [-9.4276e-01],\n",
       "        [-7.0750e-01],\n",
       "        [-9.6345e-01],\n",
       "        [-9.2401e-01],\n",
       "        [-9.5417e-01],\n",
       "        [-9.4374e-01],\n",
       "        [-9.7236e-01],\n",
       "        [-9.3367e-01],\n",
       "        [-7.2696e-01],\n",
       "        [-9.0578e-01],\n",
       "        [-9.7888e-01],\n",
       "        [-7.7160e-01],\n",
       "        [-9.5532e-01],\n",
       "        [-9.8186e-01],\n",
       "        [-7.4802e-01],\n",
       "        [-9.9053e-01],\n",
       "        [-7.9280e-01],\n",
       "        [-9.0208e-01],\n",
       "        [-9.8765e-01],\n",
       "        [-9.8841e-01],\n",
       "        [-9.8725e-01],\n",
       "        [-9.8970e-01],\n",
       "        [ 7.3829e-01],\n",
       "        [-8.8549e-01],\n",
       "        [-9.5297e-01],\n",
       "        [-7.4583e-01],\n",
       "        [-8.1491e-01],\n",
       "        [-9.7984e-01],\n",
       "        [-7.6075e-01],\n",
       "        [-3.4285e-03],\n",
       "        [-9.9214e-01],\n",
       "        [ 6.7761e-01],\n",
       "        [-7.0769e-01],\n",
       "        [-7.8776e-01],\n",
       "        [-9.2182e-01],\n",
       "        [-9.2758e-01],\n",
       "        [-2.0627e-03],\n",
       "        [-9.7712e-01],\n",
       "        [-1.8376e-03],\n",
       "        [-9.3537e-01],\n",
       "        [-9.8801e-01],\n",
       "        [-9.8304e-01],\n",
       "        [-9.4936e-01],\n",
       "        [-8.0292e-01],\n",
       "        [-8.7981e-08],\n",
       "        [-9.6329e-01],\n",
       "        [-9.7219e-01],\n",
       "        [-9.9178e-01],\n",
       "        [-9.5717e-01],\n",
       "        [-9.8991e-01],\n",
       "        [-8.4153e-01],\n",
       "        [-1.1012e-03],\n",
       "        [-7.2958e-01],\n",
       "        [-9.8940e-01],\n",
       "        [-9.8638e-01],\n",
       "        [-9.7493e-01],\n",
       "        [-9.4268e-01],\n",
       "        [-9.9237e-01],\n",
       "        [-9.9040e-01],\n",
       "        [-9.9042e-01],\n",
       "        [-8.4094e-01],\n",
       "        [-1.0080e-03],\n",
       "        [-9.8012e-01],\n",
       "        [-9.8766e-01],\n",
       "        [-9.8335e-01],\n",
       "        [-1.8953e-04],\n",
       "        [-9.6297e-01],\n",
       "        [-9.1612e-01],\n",
       "        [ 3.9700e-05],\n",
       "        [-9.9101e-01],\n",
       "        [-7.8557e-01],\n",
       "        [-9.5836e-01],\n",
       "        [-9.8764e-01],\n",
       "        [ 2.9243e-07],\n",
       "        [-9.3824e-01],\n",
       "        [-9.6738e-01],\n",
       "        [-9.7878e-01]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass(query) - forward_pass(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/llSourcell/pytorch_in_5_minutes/blob/master/demo.py\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "# dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read in relevant data\n",
    "trainData = np.loadtxt('data/trainData.txt', dtype=np.float32)\n",
    "queryData = np.loadtxt('data/queryData.txt', dtype=np.float32)\n",
    "df =  pd.read_pickle(\"./data/KNN.pkl\")\n",
    "querySize = len(queryData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE is batch size; INPUT_D is input dimension; HIDDEN_D is hidden dimension; \n",
    "BATCH_SIZE, INPUT_D, HIDDEN_D = 1000, 192, 128\n",
    "ALPHA = 5\n",
    "LEARNING_RATE = 1e-4\n",
    "K = 5\n",
    "\n",
    "# Create random Tensor for trainable features, and wrap them in Variables.\n",
    "# requires_grad=True indicates that we want to compute gradients wrt these Variables during the backward pass.\n",
    "anchors = Variable(torch.randn(HIDDEN_D, INPUT_D).type(torch.FloatTensor), requires_grad=True)\n",
    "biases = Variable(torch.ones(HIDDEN_D).type(torch.FloatTensor) + 16, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTripplet(index):\n",
    "#     point = torch.rand(3)\n",
    "#     pos = torch.rand(3)\n",
    "#     neg = torch.rand(3)\n",
    "    point = torch.tensor(queryData[index])\n",
    "    pos = torch.tensor(trainData[df.iloc[index].KNN[randint(0,K)]])\n",
    "    neg = torch.tensor(trainData[df.iloc[index].KNN[randint(K, len(df)-1)]])\n",
    "    return point, pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(query):\n",
    "    return torch.sign(torch.norm(query - anchors, 2, 1) - biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(16205.)\n",
      "1 tensor(16062.)\n",
      "2 tensor(16682.)\n",
      "3 tensor(14930.)\n",
      "4 tensor(19375.)\n",
      "5 tensor(18750.)\n",
      "6 tensor(16363.)\n",
      "7 tensor(17525.)\n",
      "8 tensor(16168.)\n",
      "9 tensor(14161.)\n",
      "10 tensor(16416.)\n",
      "11 tensor(18216.)\n",
      "12 tensor(17233.)\n",
      "13 tensor(20717.)\n",
      "14 tensor(18552.)\n",
      "15 tensor(17681.)\n",
      "16 tensor(17264.)\n",
      "17 tensor(16092.)\n",
      "18 tensor(19275.)\n",
      "19 tensor(16747.)\n",
      "20 tensor(15122.)\n",
      "21 tensor(16973.)\n",
      "22 tensor(18847.)\n",
      "23 tensor(16342.)\n",
      "24 tensor(14494.)\n",
      "25 tensor(16245.)\n",
      "26 tensor(17018.)\n",
      "27 tensor(16296.)\n",
      "28 tensor(16560.)\n",
      "29 tensor(20323.)\n",
      "30 tensor(19743.)\n",
      "31 tensor(14539.)\n",
      "32 tensor(17582.)\n",
      "33 tensor(18760.)\n",
      "34 tensor(17231.)\n",
      "35 tensor(20009.)\n",
      "36 tensor(15314.)\n",
      "37 tensor(17935.)\n",
      "38 tensor(15302.)\n",
      "39 tensor(15526.)\n",
      "40 tensor(14381.)\n",
      "41 tensor(16811.)\n",
      "42 tensor(15171.)\n",
      "43 tensor(18854.)\n",
      "44 tensor(14712.)\n",
      "45 tensor(18155.)\n",
      "46 tensor(16047.)\n",
      "47 tensor(15388.)\n",
      "48 tensor(18205.)\n",
      "49 tensor(18246.)\n",
      "50 tensor(14443.)\n",
      "51 tensor(16626.)\n",
      "52 tensor(16999.)\n",
      "53 tensor(14039.)\n",
      "54 tensor(16066.)\n",
      "55 tensor(17060.)\n",
      "56 tensor(19831.)\n",
      "57 tensor(17836.)\n",
      "58 tensor(17513.)\n",
      "59 tensor(16394.)\n",
      "60 tensor(17259.)\n",
      "61 tensor(16075.)\n",
      "62 tensor(17971.)\n",
      "63 tensor(14439.)\n",
      "64 tensor(14789.)\n",
      "65 tensor(16952.)\n",
      "66 tensor(15888.)\n",
      "67 tensor(16133.)\n",
      "68 tensor(15407.)\n",
      "69 tensor(17047.)\n",
      "70 tensor(17386.)\n",
      "71 tensor(17728.)\n",
      "72 tensor(16968.)\n",
      "73 tensor(16553.)\n",
      "74 tensor(22375.)\n",
      "75 tensor(15545.)\n",
      "76 tensor(16906.)\n",
      "77 tensor(17464.)\n",
      "78 tensor(18911.)\n",
      "79 tensor(18174.)\n",
      "80 tensor(16354.)\n",
      "81 tensor(16749.)\n",
      "82 tensor(19784.)\n",
      "83 tensor(17234.)\n",
      "84 tensor(20397.)\n",
      "85 tensor(16209.)\n",
      "86 tensor(19144.)\n",
      "87 tensor(17529.)\n",
      "88 tensor(17799.)\n",
      "89 tensor(16754.)\n",
      "90 tensor(15572.)\n",
      "91 tensor(18215.)\n",
      "92 tensor(18375.)\n",
      "93 tensor(18146.)\n",
      "94 tensor(16823.)\n",
      "95 tensor(19443.)\n",
      "96 tensor(14478.)\n",
      "97 tensor(17204.)\n",
      "98 tensor(18782.)\n",
      "99 tensor(15811.)\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "for epoch in range(100):\n",
    "    \n",
    "    #generate batch and compute collective loss for batch\n",
    "    batch_indicies = np.random.choice(querySize, BATCH_SIZE, replace=False)\n",
    "    loss = 0\n",
    "    for index in batch_indicies:\n",
    "        query, pos, neg = generateTripplet(index)\n",
    "        queryMapped, posMapped, negMapped = [forward_pass(x) for x in [query, pos, neg]]\n",
    "        pos_neg_diff = torch.norm(queryMapped-posMapped, 2, 0).pow(2) - torch.norm(queryMapped-negMapped, 2, 0).pow(2) + ALPHA\n",
    "        loss += nn.functional.relu(pos_neg_diff).sum()\n",
    "    \n",
    "    print(epoch, loss.data)\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Variables with requires_grad=True.\n",
    "    # After this we can call var.grad on variables\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    biases.data -= LEARNING_RATE * biases.grad.data\n",
    "    anchors.data -= LEARNING_RATE * anchors.grad.data\n",
    "\n",
    "    # Manually zero the gradients \n",
    "    biases.grad.data.zero_()\n",
    "    anchors.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = torch.tensor([1.,2.,3.])\n",
    "t1 = torch.tensor([[1.,1.,1.], [2.,2.,2.]])\n",
    "t2 = torch.tensor([[2.,2.,2.], [3.,3.,3.]], requires_grad = True)\n",
    "# t3 = torch.sign(torch.norm(t1 - t2, 2, 1) + biases[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

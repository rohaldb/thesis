{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/llSourcell/pytorch_in_5_minutes/blob/master/demo.py\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "from torch.nn.modules.distance import PairwiseDistance\n",
    "\n",
    "class TripletLoss(Function):\n",
    "    \n",
    "    def __init__(self, margin):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.pdist  = PairwiseDistance(2)\n",
    "        \n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_dist   = self.pdist.forward(anchor, positive).pow(2)\n",
    "        neg_dist   = self.pdist.forward(anchor, negative).pow(2)\n",
    "        hinge_dist = torch.clamp(self.margin + pos_dist - neg_dist, min = 0.0)\n",
    "        loss       = torch.mean(hinge_dist)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.3 s, sys: 8.3 s, total: 25.6 s\n",
      "Wall time: 26.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#read in relevant data\n",
    "trainData = torch.from_numpy(np.loadtxt('data/trainData.txt', dtype=np.float32))\n",
    "queryData = torch.from_numpy(np.loadtxt('data/queryData.txt', dtype=np.float32))\n",
    "df =  pd.read_pickle(\"./data/KNN.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE is batch size; INPUT_D is input dimension; OUTPUT_D is output dimension; \n",
    "BATCH_SIZE, INPUT_D, HIDDEN_D, OUTPUT_D = 1000, 192, 128, 128\n",
    "ALPHA = 0.5\n",
    "LEARNING_RATE = 1e-3\n",
    "K = 5\n",
    "\n",
    "# Create random Tensor for trainable features, and wrap them in Variables.\n",
    "# requires_grad=True indicates that we want to compute gradients wrt these Variables during the backward pass.\n",
    "anchors = Variable(torch.randn(OUTPUT_D, INPUT_D).type(torch.FloatTensor), requires_grad=True)\n",
    "# weights = Variable(torch.randn(HIDDEN_D, OUTPUT_D).type(torch.FloatTensor), requires_grad=True)\n",
    "\n",
    "# set b0 to be mean value\n",
    "aggregate = torch.zeros(OUTPUT_D)\n",
    "for point in queryData:\n",
    "    w0 = torch.norm(point.t() - anchors, 2, 1)\n",
    "    aggregate += w0\n",
    "    \n",
    "biases = Variable((aggregate/queryData.shape[0]).reshape(-1, 1), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTripplet(index):\n",
    "    point = queryData[index].reshape(-1, 1)\n",
    "    pos = trainData[df.iloc[index].KNN[randint(0,K)]].reshape(-1, 1)\n",
    "    neg = trainData[df.iloc[index].KNN[randint(K, len(df)-1)]].reshape(-1, 1)\n",
    "    return point, pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "def forward_pass(query):\n",
    "    return sigmoid(torch.norm(query.t() - anchors, 2, 1).reshape(-1, 1) - biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(507.2083)\n",
      "1 tensor(521.0921)\n",
      "2 tensor(520.4835)\n",
      "3 tensor(517.2171)\n",
      "4 tensor(511.0168)\n",
      "5 tensor(510.6352)\n",
      "6 tensor(533.2737)\n",
      "7 tensor(522.0214)\n",
      "8 tensor(519.0345)\n",
      "9 tensor(527.9480)\n",
      "10 tensor(528.4173)\n",
      "11 tensor(506.4541)\n",
      "12 tensor(513.2556)\n",
      "13 tensor(515.3956)\n",
      "14 tensor(525.0693)\n",
      "15 tensor(510.0119)\n",
      "16 tensor(525.0049)\n",
      "17 tensor(518.9528)\n",
      "18 tensor(512.3215)\n",
      "19 tensor(518.0714)\n",
      "20 tensor(518.8181)\n",
      "21 tensor(512.0618)\n",
      "22 tensor(514.3668)\n",
      "23 tensor(508.6679)\n",
      "24 tensor(518.6509)\n",
      "25 tensor(517.7710)\n",
      "26 tensor(517.2629)\n",
      "27 tensor(516.8866)\n",
      "28 tensor(506.8255)\n",
      "29 tensor(519.1831)\n",
      "30 tensor(530.7878)\n",
      "31 tensor(518.4875)\n",
      "32 tensor(516.9802)\n",
      "33 tensor(519.2198)\n",
      "34 tensor(510.8516)\n",
      "35 tensor(522.6309)\n",
      "36 tensor(530.8637)\n",
      "37 tensor(510.6067)\n",
      "38 tensor(519.1215)\n",
      "39 tensor(522.8857)\n",
      "40 tensor(521.7526)\n",
      "41 tensor(526.3864)\n",
      "42 tensor(505.8412)\n",
      "43 tensor(522.1140)\n",
      "44 tensor(515.7787)\n",
      "45 tensor(518.8862)\n",
      "46 tensor(526.0958)\n",
      "47 tensor(519.3914)\n",
      "48 tensor(503.7811)\n",
      "49 tensor(504.5177)\n",
      "50 tensor(522.3801)\n",
      "51 tensor(502.0420)\n",
      "52 tensor(515.7850)\n",
      "53 tensor(522.4328)\n",
      "54 tensor(519.9549)\n",
      "55 tensor(512.8370)\n",
      "56 tensor(510.1774)\n",
      "57 tensor(531.7269)\n",
      "58 tensor(521.8881)\n",
      "59 tensor(525.0166)\n",
      "60 tensor(519.2955)\n",
      "61 tensor(518.9467)\n",
      "62 tensor(519.6779)\n",
      "63 tensor(522.3979)\n",
      "64 tensor(508.3792)\n",
      "65 tensor(504.6389)\n",
      "66 tensor(522.2272)\n",
      "67 tensor(525.9356)\n",
      "68 tensor(513.1332)\n",
      "69 tensor(513.0270)\n",
      "70 tensor(526.6732)\n",
      "71 tensor(510.7469)\n",
      "72 tensor(530.5151)\n",
      "73 tensor(520.2626)\n",
      "74 tensor(530.9266)\n",
      "75 tensor(503.3905)\n",
      "76 tensor(521.4798)\n",
      "77 tensor(524.7347)\n",
      "78 tensor(505.9195)\n",
      "79 tensor(501.6385)\n",
      "80 tensor(525.3935)\n",
      "81 tensor(509.1785)\n",
      "82 tensor(517.4365)\n",
      "83 tensor(531.3961)\n",
      "84 tensor(515.4363)\n",
      "85 tensor(516.9768)\n",
      "86 tensor(515.3566)\n",
      "87 tensor(505.4080)\n",
      "88 tensor(514.4356)\n",
      "89 tensor(525.4488)\n",
      "90 tensor(529.5709)\n",
      "91 tensor(516.2938)\n",
      "92 tensor(516.6141)\n",
      "93 tensor(511.9836)\n",
      "94 tensor(528.7503)\n",
      "95 tensor(525.2938)\n",
      "96 tensor(523.1413)\n",
      "97 tensor(506.4390)\n",
      "98 tensor(528.5051)\n",
      "99 tensor(524.0642)\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "for epoch in range(100):\n",
    "    \n",
    "    #generate batch and compute collective loss for batch\n",
    "    batch_indicies = np.random.choice(queryData.shape[0], BATCH_SIZE, replace=False)\n",
    "    loss = 0\n",
    "    for index in batch_indicies:\n",
    "        query, pos, neg = generateTripplet(index)\n",
    "        queryMapped, posMapped, negMapped = [forward_pass(x) for x in [query, pos, neg]]\n",
    "        triplet_loss = TripletLoss(ALPHA).forward(queryMapped, posMapped, negMapped)\n",
    "        loss += triplet_loss\n",
    "    \n",
    "    print(epoch, loss.data)\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Variables with requires_grad=True.\n",
    "    # After this we can call var.grad on variables\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    biases.data -= LEARNING_RATE * biases.grad.data\n",
    "    anchors.data -= LEARNING_RATE * anchors.grad.data\n",
    "\n",
    "    # Manually zero the gradients \n",
    "    biases.grad.data.zero_()\n",
    "    anchors.grad.data.zero_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

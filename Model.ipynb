{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/llSourcell/pytorch_in_5_minutes/blob/master/demo.py\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "# dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "from torch.nn.modules.distance import PairwiseDistance\n",
    "\n",
    "class TripletLoss(Function):\n",
    "    \n",
    "    def __init__(self, margin):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.pdist  = PairwiseDistance(2)\n",
    "        \n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_dist   = self.pdist.forward(anchor, positive).pow(2)\n",
    "        neg_dist   = self.pdist.forward(anchor, negative).pow(2)\n",
    "        hinge_dist = torch.clamp(self.margin + pos_dist - neg_dist, min = 0.0)\n",
    "        loss       = torch.mean(hinge_dist)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read in relevant data\n",
    "trainData = torch.from_numpy(np.loadtxt('data/trainData.txt', dtype=np.float32))\n",
    "queryData = torch.from_numpy(np.loadtxt('data/queryData.txt', dtype=np.float32))\n",
    "df =  pd.read_pickle(\"./data/KNN.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE is batch size; INPUT_D is input dimension; OUTPUT_D is output dimension; \n",
    "BATCH_SIZE, INPUT_D, HIDDEN_D, OUTPUT_D = 1, 192, 128, 128\n",
    "ALPHA = 0.5\n",
    "LEARNING_RATE = 1e-2\n",
    "K = 5\n",
    "\n",
    "# Create random Tensor for trainable features, and wrap them in Variables.\n",
    "# requires_grad=True indicates that we want to compute gradients wrt these Variables during the backward pass.\n",
    "anchors = Variable(torch.randn(OUTPUT_D, INPUT_D).type(torch.FloatTensor), requires_grad=True)\n",
    "# weights = Variable(torch.randn(HIDDEN_D, OUTPUT_D).type(torch.FloatTensor), requires_grad=True)\n",
    "\n",
    "# set b0 to be mean value\n",
    "aggregate = torch.zeros(OUTPUT_D)\n",
    "for point in queryData[:5]:\n",
    "    w0 = torch.norm(point.t() - anchors, 2, 1)\n",
    "    aggregate += w0\n",
    "    \n",
    "biases = Variable((aggregate/queryData.shape[0]).reshape(-1, 1), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTripplet(index):\n",
    "    point = queryData[index].reshape(-1, 1)\n",
    "    pos = trainData[df.iloc[index].KNN[randint(0,K)]].reshape(-1, 1)\n",
    "    neg = trainData[df.iloc[index].KNN[randint(K, len(df)-1)]].reshape(-1, 1)\n",
    "    return point, pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(query):\n",
    "    return torch.sign(torch.norm(query.t() - anchors, 2, 1).reshape(-1, 1) - biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = torch.ones(3)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4189, 3.1514, 3.0350],\n",
       "        [2.9972, 2.3845, 2.2062]], requires_grad=True)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4189, 2.1514, 2.0350],\n",
       "        [1.9972, 1.3845, 1.2062]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors - query.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "for epoch in range(1):\n",
    "    \n",
    "    #generate batch and compute collective loss for batch\n",
    "    batch_indicies = np.random.choice(queryData.shape[0], BATCH_SIZE, replace=False)\n",
    "    loss = 0\n",
    "    for index in batch_indicies:\n",
    "        query, pos, neg = generateTripplet(index)\n",
    "        queryMapped, posMapped, negMapped = [forward_pass(x) for x in [query, pos, neg]]\n",
    "        triplet_loss = TripletLoss(ALPHA).forward(queryMapped, posMapped, negMapped)\n",
    "        loss += triplet_loss\n",
    "    \n",
    "    print(epoch, loss.data)\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Variables with requires_grad=True.\n",
    "    # After this we can call var.grad on variables\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    biases.data -= LEARNING_RATE * biases.grad.data\n",
    "    anchors.data -= LEARNING_RATE * anchors.grad.data\n",
    "\n",
    "    # Manually zero the gradients \n",
    "#     biases.grad.data.zero_()\n",
    "#     anchors.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(query.t() - anchors, 2, 1).reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21.7116, 20.0895, 19.4231,  ..., 20.2728, 18.4877, 20.6817],\n",
       "        [21.7130, 20.0909, 19.4245,  ..., 20.2742, 18.4891, 20.6831],\n",
       "        [21.7125, 20.0903, 19.4240,  ..., 20.2737, 18.4885, 20.6826],\n",
       "        ...,\n",
       "        [21.7117, 20.0896, 19.4233,  ..., 20.2730, 18.4878, 20.6819],\n",
       "        [21.7128, 20.0907, 19.4243,  ..., 20.2740, 18.4889, 20.6829],\n",
       "        [21.7130, 20.0909, 19.4245,  ..., 20.2742, 18.4891, 20.6831]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.norm(query.t() - anchors, 2, 1).reshape(-1,1) - biases).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queryMapped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.norm(query.t() - anchors, 2, 1).reshape(-1, 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2577.8486, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

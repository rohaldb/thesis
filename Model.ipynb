{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/llSourcell/pytorch_in_5_minutes/blob/master/demo.py\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "from torch.nn.modules.distance import PairwiseDistance\n",
    "\n",
    "class TripletLoss(Function):\n",
    "    \n",
    "    def __init__(self, alpha):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.pdist  = PairwiseDistance(2)\n",
    "        \n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_dist   = self.pdist.forward(anchor, positive).pow(2)\n",
    "        neg_dist   = self.pdist.forward(anchor, negative).pow(2)\n",
    "        hinge_dist = torch.clamp(self.alpha + pos_dist - neg_dist, min = 0.0)\n",
    "        loss       = torch.mean(hinge_dist)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26 s, sys: 30.7 s, total: 56.7 s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#read in relevant data\n",
    "trainData = torch.from_numpy(np.loadtxt('data/trainData.txt', dtype=np.float32))\n",
    "queryData = torch.from_numpy(np.loadtxt('data/queryData.txt', dtype=np.float32))\n",
    "df =  pd.read_pickle(\"./data/KNN.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTripplet(index):\n",
    "    point = queryData[index].reshape(-1, 1)\n",
    "#     pos = trainData[df.iloc[index].KNN[randint(0,K)]].reshape(-1, 1) # pos fom KNN\n",
    "#     negIndicies = list(range(K,K + 10)) + list(range(df.shape[0]-20, df.shape[0]-1))\n",
    "#     neg = trainData[df.iloc[index].KNN[np.random.choice(negIndicies)]].reshape(-1, 1)\n",
    "#     neg = trainData[df.iloc[index].KNN[randint(K, df.shape[0]-1)]].reshape(-1, 1)\n",
    "    pos = trainData[df.iloc[index].KNN[0]].reshape(-1, 1) # pos fom KNN\n",
    "    neg = trainData[df.iloc[index].KNN[5004]].reshape(-1, 1)\n",
    "    return point, pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "def forward_pass(query):\n",
    "    return sigmoid(torch.norm(query.t() - anchors, 2, 1).reshape(-1, 1) - biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE is batch size; INPUT_D is input dimension; OUTPUT_D is output dimension; \n",
    "BATCH_SIZE, INPUT_D, HIDDEN_D, OUTPUT_D = 10, 192, 128, 128\n",
    "ALPHA = 0.5\n",
    "LEARNING_RATE = 1e2\n",
    "K = 5\n",
    "\n",
    "def init_model():\n",
    "    print(\"--- Initialising Model Params --- \")\n",
    "    \n",
    "    anchors = Variable(torch.randn(OUTPUT_D, INPUT_D).type(torch.FloatTensor), requires_grad=True)\n",
    "    # weights = Variable(torch.randn(HIDDEN_D, OUTPUT_D).type(torch.FloatTensor), requires_grad=True)\n",
    "\n",
    "    # set biases to be mean value\n",
    "    aggregate = torch.zeros(OUTPUT_D)\n",
    "    for point in queryData:\n",
    "        w0 = torch.norm(point.t() - anchors, 2, 1)\n",
    "        aggregate += w0\n",
    "\n",
    "    biases = Variable((aggregate/queryData.shape[0]).reshape(-1, 1), requires_grad=True)\n",
    "    print(\"--- Done. Begining training ---\")\n",
    "    return anchors, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initialising Model Params --- \n",
      "--- Done. Begining training ---\n",
      "0 tensor(0.2355)\n",
      "1 tensor(0.2663)\n",
      "2 tensor(0.3368)\n",
      "3 tensor(0.3510)\n",
      "4 tensor(0.4320)\n",
      "5 tensor(0.4403)\n",
      "6 tensor(0.3730)\n",
      "7 tensor(0.4323)\n",
      "8 tensor(0.3196)\n",
      "9 tensor(0.3957)\n",
      "10 tensor(0.2928)\n",
      "11 tensor(0.3656)\n",
      "12 tensor(0.3768)\n",
      "13 tensor(0.3730)\n",
      "14 tensor(0.3298)\n",
      "15 tensor(0.4228)\n",
      "16 tensor(0.3350)\n",
      "17 tensor(0.3694)\n",
      "18 tensor(0.2834)\n",
      "19 tensor(0.3947)\n",
      "20 tensor(0.3734)\n",
      "21 tensor(0.3021)\n",
      "22 tensor(0.4551)\n",
      "23 tensor(0.4408)\n",
      "24 tensor(0.3470)\n",
      "25 tensor(0.4468)\n",
      "26 tensor(0.3623)\n",
      "27 tensor(0.3312)\n",
      "28 tensor(0.3105)\n",
      "29 tensor(0.3379)\n",
      "30 tensor(0.3874)\n",
      "31 tensor(0.3624)\n",
      "32 tensor(0.3141)\n",
      "33 tensor(0.3365)\n",
      "34 tensor(0.2891)\n",
      "35 tensor(0.3846)\n",
      "36 tensor(0.2998)\n",
      "37 tensor(0.3924)\n",
      "38 tensor(0.2779)\n",
      "39 tensor(0.3754)\n",
      "40 tensor(0.3768)\n",
      "41 tensor(0.3728)\n",
      "42 tensor(0.3337)\n",
      "43 tensor(0.2802)\n",
      "44 tensor(0.3923)\n",
      "45 tensor(0.2336)\n",
      "46 tensor(0.4020)\n",
      "47 tensor(0.3124)\n",
      "48 tensor(0.2705)\n",
      "49 tensor(0.4131)\n",
      "50 tensor(0.3653)\n",
      "51 tensor(0.3607)\n",
      "52 tensor(0.3817)\n",
      "53 tensor(0.3575)\n",
      "54 tensor(0.3968)\n",
      "55 tensor(0.3556)\n",
      "56 tensor(0.4145)\n",
      "57 tensor(0.2828)\n",
      "58 tensor(0.3143)\n",
      "59 tensor(0.3076)\n",
      "60 tensor(0.3837)\n",
      "61 tensor(0.3492)\n",
      "62 tensor(0.3973)\n",
      "63 tensor(0.3837)\n",
      "64 tensor(0.3841)\n",
      "65 tensor(0.3740)\n",
      "66 tensor(0.3879)\n",
      "67 tensor(0.3113)\n",
      "68 tensor(0.4085)\n",
      "69 tensor(0.2533)\n",
      "70 tensor(0.3335)\n",
      "71 tensor(0.2664)\n",
      "72 tensor(0.3100)\n",
      "73 tensor(0.4225)\n",
      "74 tensor(0.3720)\n",
      "75 tensor(0.2926)\n",
      "76 tensor(0.2951)\n",
      "77 tensor(0.2700)\n",
      "78 tensor(0.4374)\n",
      "79 tensor(0.4072)\n",
      "80 tensor(0.2661)\n",
      "81 tensor(0.3374)\n",
      "82 tensor(0.3182)\n",
      "83 tensor(0.3901)\n",
      "84 tensor(0.2977)\n",
      "85 tensor(0.3134)\n",
      "86 tensor(0.4469)\n",
      "87 tensor(0.3870)\n",
      "88 tensor(0.2449)\n",
      "89 tensor(0.2874)\n",
      "90 tensor(0.3688)\n",
      "91 tensor(0.3060)\n",
      "92 tensor(0.5130)\n",
      "93 tensor(0.3441)\n",
      "94 tensor(0.2831)\n",
      "95 tensor(0.3683)\n",
      "96 tensor(0.3822)\n",
      "97 tensor(0.3676)\n",
      "98 tensor(0.3014)\n",
      "99 tensor(0.3609)\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "anchors, biases = init_model()\n",
    "\n",
    "for epoch in range(100):\n",
    "\n",
    "    #generate batch and compute collective loss for batch\n",
    "    # UNSTABLE LEARNING WHEN SAMPLE SIZE > BATCH SIZE\n",
    "    batch_indicies = np.random.choice(queryData.shape[0], BATCH_SIZE, replace=False) \n",
    "    loss = 0\n",
    "    for index in batch_indicies:\n",
    "        query, pos, neg = generateTripplet(index)\n",
    "        queryMapped, posMapped, negMapped = [forward_pass(x) for x in [query, pos, neg]]\n",
    "        triplet_loss = TripletLoss(ALPHA).forward(queryMapped, posMapped, negMapped)\n",
    "        loss += triplet_loss\n",
    "    \n",
    "    loss /= BATCH_SIZE # computes mean so learning rate remains the same\n",
    "    \n",
    "    print(epoch, loss.data)\n",
    "\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    # Update params using gradient descent\n",
    "    biases.data -= LEARNING_RATE * biases.grad.data\n",
    "    anchors.data -= LEARNING_RATE * anchors.grad.data\n",
    "\n",
    "    # Manually zero the gradients \n",
    "    biases.grad.data.zero_()\n",
    "    anchors.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

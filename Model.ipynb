{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/llSourcell/pytorch_in_5_minutes/blob/master/demo.py\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "# dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read in relevant data\n",
    "trainData = np.loadtxt('data/trainData.txt', dtype=np.float32)\n",
    "queryData = np.loadtxt('data/queryData.txt', dtype=np.float32)\n",
    "df =  pd.read_pickle(\"./data/KNN.pkl\")\n",
    "querySize = len(queryData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE is batch size; INPUT_D is input dimension; HIDDEN_D is hidden dimension; \n",
    "BATCH_SIZE, INPUT_D, HIDDEN_D = 1000, 192, 128\n",
    "ALPHA = 5\n",
    "LEARNING_RATE = 1e-2\n",
    "K = 5\n",
    "\n",
    "# Create random Tensor for trainable features, and wrap them in Variables.\n",
    "# requires_grad=True indicates that we want to compute gradients wrt these Variables during the backward pass.\n",
    "anchors = Variable(torch.randn(HIDDEN_D, INPUT_D).type(torch.FloatTensor), requires_grad=True)\n",
    "biases = Variable(torch.ones(HIDDEN_D).type(torch.FloatTensor) + 16, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch.nn.modules.distance import PairwiseDistance\n",
    "\n",
    "\n",
    "class TripletLoss(Function):\n",
    "    \n",
    "    def __init__(self, margin):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.pdist  = PairwiseDistance(2)\n",
    "        \n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_dist   = self.pdist.forward(anchor, positive).pow(2)\n",
    "        neg_dist   = self.pdist.forward(anchor, negative).pow(2)\n",
    "        \n",
    "        \n",
    "        hinge_dist = torch.clamp(self.margin + pos_dist - neg_dist, min = 0.0)\n",
    "        loss       = torch.mean(hinge_dist)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTripplet(index):\n",
    "    point = torch.tensor([queryData[index]])\n",
    "    pos = torch.tensor([trainData[df.iloc[index].KNN[randint(0,K)]]])\n",
    "    neg = torch.tensor([trainData[df.iloc[index].KNN[randint(K, len(df)-1)]]])\n",
    "    return point, pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(query):\n",
    "    return torch.sign(torch.norm(query - anchors, 2, 1) - biases).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(19729.)\n",
      "1 tensor(13016.0010)\n",
      "2 tensor(15089.)\n",
      "3 tensor(15773.0010)\n",
      "4 tensor(16507.0020)\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "for epoch in range(100):\n",
    "    \n",
    "    #generate batch and compute collective loss for batch\n",
    "    batch_indicies = np.random.choice(querySize, BATCH_SIZE, replace=False)\n",
    "    loss = 0\n",
    "    for index in batch_indicies:\n",
    "        query, pos, neg = generateTripplet(index)\n",
    "        queryMapped, posMapped, negMapped = [forward_pass(x) for x in [query, pos, neg]]\n",
    "        triplet_loss = TripletLoss(ALPHA).forward(queryMapped, posMapped, negMapped)\n",
    "        loss += triplet_loss\n",
    "    \n",
    "    print(epoch, loss.data)\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Variables with requires_grad=True.\n",
    "    # After this we can call var.grad on variables\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    biases.data -= LEARNING_RATE * biases.grad.data\n",
    "    anchors.data -= LEARNING_RATE * anchors.grad.data\n",
    "\n",
    "    # Manually zero the gradients \n",
    "    biases.grad.data.zero_()\n",
    "    anchors.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000]) tensor([1.0000e-12, 1.0000e-12]) tensor([1.0000, 1.0000]) tensor(1.0000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = torch.tensor([[0.], [0.]])\n",
    "t1 = torch.tensor([[1.], [1.]])\n",
    "t2 = torch.tensor([[2.], [2.]])\n",
    "# t2 = torch.tensor([[2.,2.,2.], [3.,3.,3.]], requires_grad = True)\n",
    "# t3 = torch.sign(torch.norm(t1 - t2, 2, 1) + biases[0:2])\n",
    "TripletLoss(0).forward(t1, t2, t1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/llSourcell/pytorch_in_5_minutes/blob/master/demo.py\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from ast import literal_eval\n",
    "\n",
    "# dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read in relevant data\n",
    "trainData = np.loadtxt('data/trainData.txt', dtype=np.float32)\n",
    "queryData = np.loadtxt('data/queryData.txt', dtype=np.float32)\n",
    "df =  pd.read_pickle(\"./data/KNN.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "def generateTripplet(index):\n",
    "#     point = torch.rand(5)\n",
    "#     pos = torch.rand(5)\n",
    "#     neg = torch.rand(5)\n",
    "    point = torch.tensor(queryData[index])\n",
    "    pos = torch.tensor(trainData[df.iloc[index].KNN[randint(0,K)]])\n",
    "    neg = torch.tensor(trainData[df.iloc[index].KNN[randint(K, len(df)-1)]])\n",
    "    return point, pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE is batch size; INPUT_D is input dimension; HIDDEN_D is hidden dimension; \n",
    "BATCH_SIZE, INPUT_D, HIDDEN_D = 1, 192, 128\n",
    "ALPHA = 0.5\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# Create random Tensors to hold input and outputs, and wrap them in Variables.\n",
    "# Setting requires_grad=False indicates that we do not need to compute gradients\n",
    "# with respect to these Variables during the backward pass.\n",
    "x = Variable(torch.randn(INPUT_D).type(dtype), requires_grad=False)\n",
    "\n",
    "# Create random Tensor for weights, and wrap them in Variables.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Variables during the backward pass.\n",
    "anchors = Variable(torch.randn(HIDDEN_D, INPUT_D).type(dtype), requires_grad=True)\n",
    "biases = Variable(torch.randn(INPUT_D).type(dtype), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(query):\n",
    "    return torch.sign(torch.norm(query - anchors, 2) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "for index in range(1):\n",
    "    query, pos, neg = generateTripplet(index)\n",
    "    \n",
    "    queryMapped, posMapped, negMapped = [forward_pass(x) for x in [query, pos, neg]]\n",
    "    \n",
    "    # Compute and print loss using operations on Variables.\n",
    "    # Now loss is a Variable of shape (1,) and loss.data is a Tensor of shape\n",
    "    # (1,); loss.data[0] is a scalar value holding the loss.\n",
    "    pos_neg_diff = (torch.norm(queryMapped-posMapped, 2, 0).pow(2) - torch.norm(queryMapped-negMapped, 2, 0).pow(2) + ALPHA)\n",
    "    loss = nn.functional.relu(pos_neg_diff).sum()\n",
    "    print(index, loss.data)\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Variables with requires_grad=True.\n",
    "    # After this we can call var.grad on variables\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    biases.data -= LEARNING_RATE * biases.grad.data\n",
    "    anchors.data -= LEARNING_RATE * anchors.grad.data\n",
    "\n",
    "    # Manually zero the gradients \n",
    "    biases.grad.data.zero_()\n",
    "    anchors.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = torch.tensor([1.,2.,3.])\n",
    "t1 = torch.tensor([0.,1.,2.])\n",
    "t2 = torch.tensor([[2.,3.,4.], [5.,6.,7.]], requires_grad = True)\n",
    "t3 = torch.sign(torch.norm(t1 - t2, 2, 1) + biases[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
